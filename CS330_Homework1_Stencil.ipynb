{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS330_Homework1_Stencil.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwoncpark/cs330-deep-multitask-meta-learning/blob/master/CS330_Homework1_Stencil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvkoC8rAYBE7"
      },
      "source": [
        "\n",
        "##Setup\n",
        "\n",
        "You will need to make a copy of this Colab notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q4lGYC_E6QQ"
      },
      "source": [
        "import os\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "# Need to download the Omniglot dataset -- DON'T MODIFY THIS CELL\n",
        "if not os.path.isdir('./omniglot_resized'):\n",
        "    gdd.download_file_from_google_drive(file_id='1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI',\n",
        "                                        dest_path='./omniglot_resized.zip',\n",
        "                                        unzip=True)\n",
        "    \n",
        "assert os.path.isdir('./omniglot_resized')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucYsULp9HUJy"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from scipy import misc\n",
        "\n",
        "\n",
        "def get_images(paths, labels, nb_samples=None, shuffle=True):\n",
        "    \"\"\"\n",
        "    Takes a set of character folders and labels and returns paths to image files\n",
        "    paired with labels.\n",
        "    Args:\n",
        "        paths: A list of character folders\n",
        "        labels: List or numpy array of same length as paths\n",
        "        nb_samples: Number of images to retrieve per character\n",
        "    Returns:\n",
        "        List of (label, image_path) tuples\n",
        "    \"\"\"\n",
        "    if nb_samples is not None:\n",
        "        # Draw K random samples (images) from each character class\n",
        "        sampler = lambda x: random.sample(x, nb_samples)\n",
        "    else:\n",
        "        sampler = lambda x: x\n",
        "    images_labels = [(i, os.path.join(path, image))\n",
        "                     for i, path in zip(labels, paths)\n",
        "                     for image in sampler(os.listdir(path))] # choose nb_samples images from character folder path\n",
        "    if shuffle:\n",
        "        # Permute order of tuples, maintaining each tuple pairing\n",
        "        random.shuffle(images_labels)\n",
        "    return images_labels\n",
        "\n",
        "\n",
        "def image_file_to_array(filename, dim_input):\n",
        "    \"\"\"\n",
        "    Takes an image path and returns numpy array\n",
        "    Args:\n",
        "        filename: Image filename\n",
        "        dim_input: Flattened shape of image\n",
        "    Returns:\n",
        "        1 channel image\n",
        "    \"\"\"\n",
        "    import imageio\n",
        "    image = imageio.imread(filename)  # misc.imread(filename)\n",
        "    image = image.reshape([dim_input])\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    image = 1.0 - image\n",
        "    return image\n",
        "\n",
        "\n",
        "class DataGenerator(object):\n",
        "    \"\"\"\n",
        "    Data Generator capable of generating batches of Omniglot data.\n",
        "    A \"class\" is considered a class of omniglot digits.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, num_samples_per_class, config={}):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_classes: Number of classes for classification (K-way)\n",
        "            num_samples_per_class: num samples to generate per class in one batch\n",
        "            batch_size: size of meta batch size (e.g. number of functions)\n",
        "        \"\"\"\n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        data_folder = config.get('data_folder', './omniglot_resized')\n",
        "        self.img_size = config.get('img_size', (28, 28))\n",
        "\n",
        "        self.dim_input = np.prod(self.img_size)\n",
        "        self.dim_output = self.num_classes\n",
        "\n",
        "        # List of length 1623 (for 1623 characters)\n",
        "        # Each element is a path nested with language (family),\n",
        "        # e.g. ./omniglot_resized/Braille/character23\n",
        "        character_folders = [os.path.join(data_folder, family, character)\n",
        "                             for family in os.listdir(data_folder)\n",
        "                             if os.path.isdir(os.path.join(data_folder, family))\n",
        "                             for character in os.listdir(os.path.join(data_folder, family))\n",
        "                             if os.path.isdir(os.path.join(data_folder, family, character))]\n",
        "\n",
        "        random.seed(1)\n",
        "        random.shuffle(character_folders)\n",
        "        num_val = 100\n",
        "        num_train = 1100\n",
        "        self.metatrain_character_folders = character_folders[: num_train]\n",
        "        self.metaval_character_folders = character_folders[\n",
        "            num_train:num_train + num_val]\n",
        "        self.metatest_character_folders = character_folders[\n",
        "            num_train + num_val:]\n",
        "\n",
        "    def sample_batch(self, batch_type, batch_size):\n",
        "        \"\"\"\n",
        "        Samples a batch for training, validation, or testing\n",
        "        Args:\n",
        "            batch_type: train/val/test\n",
        "        Returns:\n",
        "            A a tuple of (1) Image batch and (2) Label batch where\n",
        "            image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n",
        "            where B is batch size, K is number of samples per class, N is number of classes\n",
        "        \"\"\"\n",
        "        if batch_type == \"train\":\n",
        "            folders = self.metatrain_character_folders\n",
        "        elif batch_type == \"val\":\n",
        "            folders = self.metaval_character_folders\n",
        "        else:\n",
        "            folders = self.metatest_character_folders\n",
        "\n",
        "        #############################\n",
        "        #### YOUR CODE GOES HERE ####\n",
        "        folders = np.array(folders)\n",
        "        # Initialize image and label arrays to output\n",
        "        all_image_batches = np.empty([batch_size, self.num_samples_per_class, self.num_classes, self.dim_input])\n",
        "        all_label_batches = np.empty([batch_size, self.num_samples_per_class, self.num_classes, self.num_classes])\n",
        "        for b in range(batch_size):\n",
        "          # Sample K images in N classes from the correct folder\n",
        "          sampled_class_folders = folders[random.sample(range(len(folders)), self.num_classes)] # folders of sampled N classes for this batch\n",
        "          labels = np.arange(self.num_classes) # arbitrary integer labels for the N classes\n",
        "          labels_images = get_images(sampled_class_folders, labels, nb_samples=self.num_samples_per_class, shuffle=False) # list of length N*K\n",
        "          for i, (label, img_path) in enumerate(labels_images):\n",
        "            k = i%self.num_samples_per_class # index for image in given batch and class\n",
        "            # Populate image\n",
        "            img = image_file_to_array(img_path, self.dim_input).flatten()\n",
        "            all_image_batches[b, k, label, :] = img\n",
        "            # Populate one-hot label\n",
        "            one_hot = np.eye(self.num_classes)[label]\n",
        "            all_label_batches[b, k, label, :] = one_hot\n",
        "        # Shuffle images and labels of last N examples (query examples) for each batch\n",
        "        indices_along_N = np.arange(self.num_classes)\n",
        "        np.random.shuffle(indices_along_N)\n",
        "        all_image_batches[:, -1, :, :] = all_image_batches[:, -1, indices_along_N, :]\n",
        "        all_label_batches[:, -1, :, :] = all_label_batches[:, -1, indices_along_N, :]\n",
        "        #############################\n",
        "\n",
        "        return all_image_batches.astype(np.float32), all_label_batches.astype(np.float32)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPSDhgm4tlFc",
        "outputId": "66ace95f-6606-4846-ca41-0302360c3744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "N = 3\n",
        "K = 4\n",
        "data_gen = DataGenerator(num_classes=N, num_samples_per_class=K)\n",
        "images, labels = data_gen.sample_batch('train', batch_size=1)\n",
        "print(\"Images batch shape:\", images.shape)\n",
        "print(\"image label\")\n",
        "print(images[:, :, :, 0])\n",
        "print(\"Labels batch shape:\", labels.shape)\n",
        "print(labels)\n",
        "plt.figure(figsize=(16, 16))\n",
        "count = 0\n",
        "for n in range(N):\n",
        "    for k in range(K):\n",
        "        plt.subplot(N, K, count + 1)\n",
        "        plt.title(\"Class {:d}, sample {:d}\".format(n, k))\n",
        "        img = images[0, k, n].reshape((28, 28))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off');\n",
        "        count += 1\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images batch shape: (1, 4, 3, 784)\n",
            "image label\n",
            "[[[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]]\n",
            "Labels batch shape: (1, 4, 3, 3)\n",
            "[[[[1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 0. 1.]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x1152 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yvqTOqTHVA9"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Memory-augmented neural network\n",
        "class MANN(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes, samples_per_class):\n",
        "        super(MANN, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.samples_per_class = samples_per_class # K+1, not just K\n",
        "        self.layer1 = tf.keras.layers.LSTM(128, return_sequences=True)\n",
        "        self.layer2 = tf.keras.layers.LSTM(num_classes, return_sequences=True)\n",
        "\n",
        "    def call(self, input_images, input_labels):\n",
        "        \"\"\"\n",
        "        MANN\n",
        "        Args:\n",
        "            input_images: [B, K+1, N, 784] flattened images\n",
        "            labels: [B, K+1, N, N] ground truth labels\n",
        "        Returns:\n",
        "            [B, K+1, N, N] predictions\n",
        "        \"\"\"\n",
        "        #############################\n",
        "        #### YOUR CODE GOES HERE ####\n",
        "        batch_size, _, _, pix_dim = input_images.shape\n",
        "        # Replace query labels with 0\n",
        "        support_labels = tf.unstack(input_labels, axis=1)[:-1] # list of length K+1\n",
        "        all_zeros_query_label = tf.zeros((batch_size, self.num_classes, self.num_classes)) # [B, N, N]\n",
        "        updated_input_labels = tf.stack(support_labels + [all_zeros_query_label], axis=1) # [B, K+1, N, N]\n",
        "        # Concat meta-training support with query\n",
        "        concat_input = tf.concat([input_images, updated_input_labels], axis=-1) # [B, K+1, N, N+784]\n",
        "        # Merge axes 1, 2\n",
        "        concat_input = tf.reshape(concat_input, [batch_size, -1, pix_dim + self.num_classes]) # [B, (K+1)N, N+784]\n",
        "        hidden = self.layer1(concat_input) # [B, K+1, 128]\n",
        "        out = self.layer2(hidden) # [B, (K+1)N, N]\n",
        "        # Separate back axes 1, 2\n",
        "        out = tf.reshape(out, [batch_size, self.samples_per_class, self.num_classes, self.num_classes]) # [B, K+1, N, N]\n",
        "        #############################\n",
        "        return out\n",
        "\n",
        "    def loss_function(self, preds, labels):\n",
        "        \"\"\"\n",
        "        Computes MANN loss\n",
        "        Args:\n",
        "            preds: [B, K+1, N, N] network output\n",
        "            labels: [B, K+1, N, N] labels\n",
        "        Returns:\n",
        "            scalar loss\n",
        "        \"\"\"\n",
        "        #############################\n",
        "        #### YOUR CODE GOES HERE ####\n",
        "        query_labels = labels[:, -1, :, :] \n",
        "        query_preds = preds[:, -1, :, :]\n",
        "        loss = tf.math.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, preds, axis=-1)) # also tf.keras.categorical_crossentropy\n",
        "        return loss\n",
        "        #############################\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels, model, optim, eval=False):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, labels)\n",
        "        loss = model.loss_function(predictions, labels)\n",
        "    if not eval:\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return predictions, loss\n",
        "\n",
        "\n",
        "def main(num_classes=5, num_samples=1, meta_batch_size=16, random_seed=1234):\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    tf.random.set_seed(random_seed)\n",
        "\n",
        "    data_generator = DataGenerator(num_classes, num_samples + 1)\n",
        "\n",
        "    o = MANN(num_classes, num_samples + 1)\n",
        "    optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    test_loss_every100 = []\n",
        "    test_acc_every100 = []\n",
        "    for step in range(25000):\n",
        "        i, l = data_generator.sample_batch('train', meta_batch_size)\n",
        "        _, ls = train_step(i, l, o, optim)\n",
        "\n",
        "        if (step + 1) % 100 == 0:\n",
        "            print(\"*\" * 5 + \"Iter \" + str(step + 1) + \"*\" * 5)\n",
        "            i, l = data_generator.sample_batch('test', 100)\n",
        "            pred, tls = train_step(i, l, o, optim, eval=True)\n",
        "            print(\"Train Loss:\", ls.numpy(), \"Test Loss:\", tls.numpy())\n",
        "            pred = tf.reshape(pred, [-1, num_samples + 1, num_classes, num_classes])\n",
        "            pred = tf.math.argmax(pred[:, -1, :, :], axis=2)\n",
        "            l = tf.math.argmax(l[:, -1, :, :], axis=2)\n",
        "            test_acc = tf.reduce_mean(tf.cast(tf.math.equal(pred, l), tf.float32)).numpy()\n",
        "            print(\"Test Accuracy\", test_acc)\n",
        "            test_loss_every100.append(tls.numpy())\n",
        "            test_acc_every100.append(test_acc)\n",
        "    return test_loss_every100, test_acc_every100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQxHeIvUIp7",
        "outputId": "ba179cc1-b030-4262-87cf-c5d999b8fd44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        }
      },
      "source": [
        "\n",
        "data_generator = DataGenerator(3, 1 + 1)\n",
        "\n",
        "i, l = data_generator.sample_batch('train', 1)\n",
        "plt.imshow(i[0, -1, 0, :].reshape(28, 28))\n",
        "print(i[0, -1, 0, 0])\n",
        "print(l[0, -1, 0, :])\n",
        "plt.show()\n",
        "plt.imshow(i[0, -1, 1, :].reshape(28, 28))\n",
        "print(i[0, -1, 1, 0])\n",
        "print(l[0, -1, 1, :])\n",
        "plt.show()\n",
        "plt.imshow(i[0, -1, 2, :].reshape(28, 28))\n",
        "print(i[0, -1, 2, 0])\n",
        "print(l[0, -1, 2, :])\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "[0. 1. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "[0. 0. 1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "[1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21B46civWgun",
        "outputId": "e921fa8c-31f8-4160-ad95-4868b4bc2ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        }
      },
      "source": [
        "plt.imshow(i[0, 0, 0, :].reshape(28, 28))\n",
        "print(i[0, 0, 0, 0])\n",
        "print(l[0, 0, 0, :])\n",
        "plt.show()\n",
        "plt.imshow(i[0, 0, 1, :].reshape(28, 28))\n",
        "print(i[0, 0, 1, 0])\n",
        "print(l[0, 0, 1, :])\n",
        "plt.show()\n",
        "plt.imshow(i[0, 0, 2, :].reshape(28, 28))\n",
        "print(i[0, 0, 2, 0])\n",
        "print(l[0, 0, 2, :])\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "[1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "[0. 1. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "[0. 0. 1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idNvAFAJWxQH"
      },
      "source": [
        "#results = main(num_classes=5, num_samples=1, meta_batch_size=16, random_seed=1234)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si10vH_0SH_y",
        "outputId": "80cc6ddd-a715-4c21-f083-7e05017ff9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "tf.config.run_functions_eagerly(True)\n",
        "#results = main(num_classes=5, num_samples=1, meta_batch_size=16, random_seed=1234)\n",
        "#############################\n",
        "#### YOUR CODE GOES HERE ####\n",
        "test_loss_dict = {}\n",
        "test_acc_dict = {}\n",
        "K_N_grid = [(1, 2), (1, 3), (1, 4), (5, 4)]\n",
        "for K, N in K_N_grid:\n",
        "  print(\"K: {:d}, N: {:d}\".format(K, N))\n",
        "  test_loss, test_acc = main(num_classes=N, num_samples=K, meta_batch_size=16, random_seed=1234)\n",
        "  test_loss_dict[(K, N)] = test_loss\n",
        "  test_acc_dict[(K, N)] = test_acc\n",
        "#############################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K: 1, N: 2\n",
            "*****Iter 100*****\n",
            "Train Loss: 0.5118209 Test Loss: 0.43019032\n",
            "Test Accuracy 0.5\n",
            "*****Iter 200*****\n",
            "Train Loss: 0.43442917 Test Loss: 0.45653072\n",
            "Test Accuracy 0.5\n",
            "*****Iter 300*****\n",
            "Train Loss: 0.4233843 Test Loss: 0.45956275\n",
            "Test Accuracy 0.5\n",
            "*****Iter 400*****\n",
            "Train Loss: 0.44890168 Test Loss: 0.43026662\n",
            "Test Accuracy 0.5\n",
            "*****Iter 500*****\n",
            "Train Loss: 0.42507318 Test Loss: 0.43418425\n",
            "Test Accuracy 0.5\n",
            "*****Iter 600*****\n",
            "Train Loss: 0.4018281 Test Loss: 0.44898197\n",
            "Test Accuracy 0.5\n",
            "*****Iter 700*****\n",
            "Train Loss: 0.4157128 Test Loss: 0.40647912\n",
            "Test Accuracy 0.5\n",
            "*****Iter 800*****\n",
            "Train Loss: 0.43370232 Test Loss: 0.4292852\n",
            "Test Accuracy 0.5\n",
            "*****Iter 900*****\n",
            "Train Loss: 0.38838202 Test Loss: 0.42291108\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1000*****\n",
            "Train Loss: 0.4283387 Test Loss: 0.4318209\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1100*****\n",
            "Train Loss: 0.41389528 Test Loss: 0.4183983\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1200*****\n",
            "Train Loss: 0.4512925 Test Loss: 0.42075488\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1300*****\n",
            "Train Loss: 0.40741628 Test Loss: 0.43587676\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1400*****\n",
            "Train Loss: 0.43142235 Test Loss: 0.4339397\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1500*****\n",
            "Train Loss: 0.43014842 Test Loss: 0.41715348\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1600*****\n",
            "Train Loss: 0.42198354 Test Loss: 0.4296192\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1700*****\n",
            "Train Loss: 0.4407624 Test Loss: 0.4156427\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1800*****\n",
            "Train Loss: 0.417009 Test Loss: 0.43233407\n",
            "Test Accuracy 0.5\n",
            "*****Iter 1900*****\n",
            "Train Loss: 0.40629303 Test Loss: 0.41808206\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2000*****\n",
            "Train Loss: 0.43174657 Test Loss: 0.4081015\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2100*****\n",
            "Train Loss: 0.418021 Test Loss: 0.41653672\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2200*****\n",
            "Train Loss: 0.42200577 Test Loss: 0.41548827\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2300*****\n",
            "Train Loss: 0.42480463 Test Loss: 0.4171099\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2400*****\n",
            "Train Loss: 0.4184506 Test Loss: 0.4306455\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2500*****\n",
            "Train Loss: 0.4156246 Test Loss: 0.4345292\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2600*****\n",
            "Train Loss: 0.44943073 Test Loss: 0.4224986\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2700*****\n",
            "Train Loss: 0.4253071 Test Loss: 0.42854884\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2800*****\n",
            "Train Loss: 0.42638847 Test Loss: 0.42400032\n",
            "Test Accuracy 0.5\n",
            "*****Iter 2900*****\n",
            "Train Loss: 0.41639027 Test Loss: 0.41331467\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3000*****\n",
            "Train Loss: 0.42085445 Test Loss: 0.42295116\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3100*****\n",
            "Train Loss: 0.4424546 Test Loss: 0.4211486\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3200*****\n",
            "Train Loss: 0.43770224 Test Loss: 0.4271853\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3300*****\n",
            "Train Loss: 0.42447034 Test Loss: 0.41911724\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3400*****\n",
            "Train Loss: 0.4510936 Test Loss: 0.40968624\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3500*****\n",
            "Train Loss: 0.42867875 Test Loss: 0.41482666\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3600*****\n",
            "Train Loss: 0.43615028 Test Loss: 0.42360657\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3700*****\n",
            "Train Loss: 0.42261875 Test Loss: 0.4056504\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3800*****\n",
            "Train Loss: 0.4307729 Test Loss: 0.4295272\n",
            "Test Accuracy 0.5\n",
            "*****Iter 3900*****\n",
            "Train Loss: 0.4297319 Test Loss: 0.43351606\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4000*****\n",
            "Train Loss: 0.42531082 Test Loss: 0.40476882\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4100*****\n",
            "Train Loss: 0.39468083 Test Loss: 0.42852792\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4200*****\n",
            "Train Loss: 0.41964835 Test Loss: 0.41305652\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4300*****\n",
            "Train Loss: 0.42687944 Test Loss: 0.42856422\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4400*****\n",
            "Train Loss: 0.4412723 Test Loss: 0.41423565\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4500*****\n",
            "Train Loss: 0.4229998 Test Loss: 0.42005852\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4600*****\n",
            "Train Loss: 0.40864438 Test Loss: 0.40421113\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4700*****\n",
            "Train Loss: 0.39340767 Test Loss: 0.41210443\n",
            "Test Accuracy 0.495\n",
            "*****Iter 4800*****\n",
            "Train Loss: 0.4327125 Test Loss: 0.43101108\n",
            "Test Accuracy 0.5\n",
            "*****Iter 4900*****\n",
            "Train Loss: 0.4349615 Test Loss: 0.4278695\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5000*****\n",
            "Train Loss: 0.4494804 Test Loss: 0.4566766\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5100*****\n",
            "Train Loss: 0.41695544 Test Loss: 0.40894103\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5200*****\n",
            "Train Loss: 0.4255887 Test Loss: 0.41979507\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5300*****\n",
            "Train Loss: 0.4119234 Test Loss: 0.41484413\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5400*****\n",
            "Train Loss: 0.41545948 Test Loss: 0.42342883\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5500*****\n",
            "Train Loss: 0.41435492 Test Loss: 0.41560367\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5600*****\n",
            "Train Loss: 0.41169757 Test Loss: 0.4275822\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5700*****\n",
            "Train Loss: 0.39239168 Test Loss: 0.4345583\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5800*****\n",
            "Train Loss: 0.43266976 Test Loss: 0.45108908\n",
            "Test Accuracy 0.5\n",
            "*****Iter 5900*****\n",
            "Train Loss: 0.39345196 Test Loss: 0.41802308\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6000*****\n",
            "Train Loss: 0.43692866 Test Loss: 0.4140709\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6100*****\n",
            "Train Loss: 0.42691153 Test Loss: 0.41660836\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6200*****\n",
            "Train Loss: 0.42167827 Test Loss: 0.42008328\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6300*****\n",
            "Train Loss: 0.39902702 Test Loss: 0.42241105\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6400*****\n",
            "Train Loss: 0.42179966 Test Loss: 0.41322854\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6500*****\n",
            "Train Loss: 0.45330626 Test Loss: 0.43879494\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6600*****\n",
            "Train Loss: 0.39714253 Test Loss: 0.42788273\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6700*****\n",
            "Train Loss: 0.43492392 Test Loss: 0.4075978\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6800*****\n",
            "Train Loss: 0.41063827 Test Loss: 0.41880155\n",
            "Test Accuracy 0.5\n",
            "*****Iter 6900*****\n",
            "Train Loss: 0.3819542 Test Loss: 0.41663468\n",
            "Test Accuracy 0.5\n",
            "*****Iter 7000*****\n",
            "Train Loss: 0.34870744 Test Loss: 0.44705924\n",
            "Test Accuracy 0.565\n",
            "*****Iter 7100*****\n",
            "Train Loss: 0.4131685 Test Loss: 0.3659096\n",
            "Test Accuracy 0.64\n",
            "*****Iter 7200*****\n",
            "Train Loss: 0.35134417 Test Loss: 0.35124394\n",
            "Test Accuracy 0.705\n",
            "*****Iter 7300*****\n",
            "Train Loss: 0.34978092 Test Loss: 0.38064346\n",
            "Test Accuracy 0.59\n",
            "*****Iter 7400*****\n",
            "Train Loss: 0.399755 Test Loss: 0.3571801\n",
            "Test Accuracy 0.595\n",
            "*****Iter 7500*****\n",
            "Train Loss: 0.35572195 Test Loss: 0.35729373\n",
            "Test Accuracy 0.615\n",
            "*****Iter 7600*****\n",
            "Train Loss: 0.35098425 Test Loss: 0.36471894\n",
            "Test Accuracy 0.61\n",
            "*****Iter 7700*****\n",
            "Train Loss: 0.36243346 Test Loss: 0.35725147\n",
            "Test Accuracy 0.64\n",
            "*****Iter 7800*****\n",
            "Train Loss: 0.3430457 Test Loss: 0.35382035\n",
            "Test Accuracy 0.645\n",
            "*****Iter 7900*****\n",
            "Train Loss: 0.3571952 Test Loss: 0.40297353\n",
            "Test Accuracy 0.595\n",
            "*****Iter 8000*****\n",
            "Train Loss: 0.46044952 Test Loss: 0.3041\n",
            "Test Accuracy 0.795\n",
            "*****Iter 8100*****\n",
            "Train Loss: 0.30434576 Test Loss: 0.3988361\n",
            "Test Accuracy 0.645\n",
            "*****Iter 8200*****\n",
            "Train Loss: 0.24923539 Test Loss: 0.28626585\n",
            "Test Accuracy 0.905\n",
            "*****Iter 8300*****\n",
            "Train Loss: 0.30972838 Test Loss: 0.2973639\n",
            "Test Accuracy 0.885\n",
            "*****Iter 8400*****\n",
            "Train Loss: 0.35778844 Test Loss: 0.29855555\n",
            "Test Accuracy 0.88\n",
            "*****Iter 8500*****\n",
            "Train Loss: 0.25072554 Test Loss: 0.3027326\n",
            "Test Accuracy 0.87\n",
            "*****Iter 8600*****\n",
            "Train Loss: 0.30360347 Test Loss: 0.320082\n",
            "Test Accuracy 0.83\n",
            "*****Iter 8700*****\n",
            "Train Loss: 0.37540457 Test Loss: 0.39635414\n",
            "Test Accuracy 0.69\n",
            "*****Iter 8800*****\n",
            "Train Loss: 0.3751527 Test Loss: 0.2988199\n",
            "Test Accuracy 0.845\n",
            "*****Iter 8900*****\n",
            "Train Loss: 0.32117236 Test Loss: 0.33986342\n",
            "Test Accuracy 0.785\n",
            "*****Iter 9000*****\n",
            "Train Loss: 0.26372746 Test Loss: 0.29613233\n",
            "Test Accuracy 0.87\n",
            "*****Iter 9100*****\n",
            "Train Loss: 0.2651272 Test Loss: 0.301605\n",
            "Test Accuracy 0.83\n",
            "*****Iter 9200*****\n",
            "Train Loss: 0.3419912 Test Loss: 0.28394908\n",
            "Test Accuracy 0.87\n",
            "*****Iter 9300*****\n",
            "Train Loss: 0.37454134 Test Loss: 0.2658289\n",
            "Test Accuracy 0.895\n",
            "*****Iter 9400*****\n",
            "Train Loss: 0.3085296 Test Loss: 0.33629665\n",
            "Test Accuracy 0.78\n",
            "*****Iter 9500*****\n",
            "Train Loss: 0.24326803 Test Loss: 0.294418\n",
            "Test Accuracy 0.85\n",
            "*****Iter 9600*****\n",
            "Train Loss: 0.28000894 Test Loss: 0.2749053\n",
            "Test Accuracy 0.89\n",
            "*****Iter 9700*****\n",
            "Train Loss: 0.30293107 Test Loss: 0.2781149\n",
            "Test Accuracy 0.88\n",
            "*****Iter 9800*****\n",
            "Train Loss: 0.32809365 Test Loss: 0.34854293\n",
            "Test Accuracy 0.755\n",
            "*****Iter 9900*****\n",
            "Train Loss: 0.35815066 Test Loss: 0.30010602\n",
            "Test Accuracy 0.85\n",
            "*****Iter 10000*****\n",
            "Train Loss: 0.28630036 Test Loss: 0.29908273\n",
            "Test Accuracy 0.85\n",
            "*****Iter 10100*****\n",
            "Train Loss: 0.28996027 Test Loss: 0.3293131\n",
            "Test Accuracy 0.785\n",
            "*****Iter 10200*****\n",
            "Train Loss: 0.36165422 Test Loss: 0.31695724\n",
            "Test Accuracy 0.825\n",
            "*****Iter 10300*****\n",
            "Train Loss: 0.27236372 Test Loss: 0.28294036\n",
            "Test Accuracy 0.865\n",
            "*****Iter 10400*****\n",
            "Train Loss: 0.28847307 Test Loss: 0.29479325\n",
            "Test Accuracy 0.86\n",
            "*****Iter 10500*****\n",
            "Train Loss: 0.23270422 Test Loss: 0.25977004\n",
            "Test Accuracy 0.925\n",
            "*****Iter 10600*****\n",
            "Train Loss: 0.28268373 Test Loss: 0.27707103\n",
            "Test Accuracy 0.87\n",
            "*****Iter 10700*****\n",
            "Train Loss: 0.35859358 Test Loss: 0.29452392\n",
            "Test Accuracy 0.855\n",
            "*****Iter 10800*****\n",
            "Train Loss: 0.3526669 Test Loss: 0.27038333\n",
            "Test Accuracy 0.895\n",
            "*****Iter 10900*****\n",
            "Train Loss: 0.2526667 Test Loss: 0.25928298\n",
            "Test Accuracy 0.92\n",
            "*****Iter 11000*****\n",
            "Train Loss: 0.2486631 Test Loss: 0.27586633\n",
            "Test Accuracy 0.885\n",
            "*****Iter 11100*****\n",
            "Train Loss: 0.28742048 Test Loss: 0.28127268\n",
            "Test Accuracy 0.88\n",
            "*****Iter 11200*****\n",
            "Train Loss: 0.2526075 Test Loss: 0.27442446\n",
            "Test Accuracy 0.875\n",
            "*****Iter 11300*****\n",
            "Train Loss: 0.25536522 Test Loss: 0.26706347\n",
            "Test Accuracy 0.9\n",
            "*****Iter 11400*****\n",
            "Train Loss: 0.27733007 Test Loss: 0.37191504\n",
            "Test Accuracy 0.735\n",
            "*****Iter 11500*****\n",
            "Train Loss: 0.25333452 Test Loss: 0.31385997\n",
            "Test Accuracy 0.84\n",
            "*****Iter 11600*****\n",
            "Train Loss: 0.2762913 Test Loss: 0.29444256\n",
            "Test Accuracy 0.845\n",
            "*****Iter 11700*****\n",
            "Train Loss: 0.28716624 Test Loss: 0.26869023\n",
            "Test Accuracy 0.885\n",
            "*****Iter 11800*****\n",
            "Train Loss: 0.31758577 Test Loss: 0.24898078\n",
            "Test Accuracy 0.93\n",
            "*****Iter 11900*****\n",
            "Train Loss: 0.3511365 Test Loss: 0.30320033\n",
            "Test Accuracy 0.83\n",
            "*****Iter 12000*****\n",
            "Train Loss: 0.47561306 Test Loss: 0.31734326\n",
            "Test Accuracy 0.82\n",
            "*****Iter 12100*****\n",
            "Train Loss: 0.33626702 Test Loss: 0.28547132\n",
            "Test Accuracy 0.87\n",
            "*****Iter 12200*****\n",
            "Train Loss: 0.22260155 Test Loss: 0.27525285\n",
            "Test Accuracy 0.88\n",
            "*****Iter 12300*****\n",
            "Train Loss: 0.22971997 Test Loss: 0.25628293\n",
            "Test Accuracy 0.925\n",
            "*****Iter 12400*****\n",
            "Train Loss: 0.27987626 Test Loss: 0.31883788\n",
            "Test Accuracy 0.8\n",
            "*****Iter 12500*****\n",
            "Train Loss: 0.23161012 Test Loss: 0.28915864\n",
            "Test Accuracy 0.85\n",
            "*****Iter 12600*****\n",
            "Train Loss: 0.21716943 Test Loss: 0.3177799\n",
            "Test Accuracy 0.82\n",
            "*****Iter 12700*****\n",
            "Train Loss: 0.35773584 Test Loss: 0.24429135\n",
            "Test Accuracy 0.92\n",
            "*****Iter 12800*****\n",
            "Train Loss: 0.26632935 Test Loss: 0.31719825\n",
            "Test Accuracy 0.825\n",
            "*****Iter 12900*****\n",
            "Train Loss: 0.27413958 Test Loss: 0.3087772\n",
            "Test Accuracy 0.82\n",
            "*****Iter 13000*****\n",
            "Train Loss: 0.24489087 Test Loss: 0.32104367\n",
            "Test Accuracy 0.81\n",
            "*****Iter 13100*****\n",
            "Train Loss: 0.24657384 Test Loss: 0.27599525\n",
            "Test Accuracy 0.875\n",
            "*****Iter 13200*****\n",
            "Train Loss: 0.24944082 Test Loss: 0.27535394\n",
            "Test Accuracy 0.89\n",
            "*****Iter 13300*****\n",
            "Train Loss: 0.24690896 Test Loss: 0.2741505\n",
            "Test Accuracy 0.89\n",
            "*****Iter 13400*****\n",
            "Train Loss: 0.23141591 Test Loss: 0.33411705\n",
            "Test Accuracy 0.785\n",
            "*****Iter 13500*****\n",
            "Train Loss: 0.31517985 Test Loss: 0.27168536\n",
            "Test Accuracy 0.885\n",
            "*****Iter 13600*****\n",
            "Train Loss: 0.34940678 Test Loss: 0.32003716\n",
            "Test Accuracy 0.805\n",
            "*****Iter 13700*****\n",
            "Train Loss: 0.34906328 Test Loss: 0.25876436\n",
            "Test Accuracy 0.9\n",
            "*****Iter 13800*****\n",
            "Train Loss: 0.3195284 Test Loss: 0.2604895\n",
            "Test Accuracy 0.915\n",
            "*****Iter 13900*****\n",
            "Train Loss: 0.20568678 Test Loss: 0.25058836\n",
            "Test Accuracy 0.92\n",
            "*****Iter 14000*****\n",
            "Train Loss: 0.25300515 Test Loss: 0.28429416\n",
            "Test Accuracy 0.86\n",
            "*****Iter 14100*****\n",
            "Train Loss: 0.2700204 Test Loss: 0.27741846\n",
            "Test Accuracy 0.875\n",
            "*****Iter 14200*****\n",
            "Train Loss: 0.25704685 Test Loss: 0.26938826\n",
            "Test Accuracy 0.885\n",
            "*****Iter 14300*****\n",
            "Train Loss: 0.2946206 Test Loss: 0.2764854\n",
            "Test Accuracy 0.895\n",
            "*****Iter 14400*****\n",
            "Train Loss: 0.24148381 Test Loss: 0.29979014\n",
            "Test Accuracy 0.85\n",
            "*****Iter 14500*****\n",
            "Train Loss: 0.31218106 Test Loss: 0.27278173\n",
            "Test Accuracy 0.88\n",
            "*****Iter 14600*****\n",
            "Train Loss: 0.27257487 Test Loss: 0.26329058\n",
            "Test Accuracy 0.915\n",
            "*****Iter 14700*****\n",
            "Train Loss: 0.27749294 Test Loss: 0.3244219\n",
            "Test Accuracy 0.805\n",
            "*****Iter 14800*****\n",
            "Train Loss: 0.23885085 Test Loss: 0.26031122\n",
            "Test Accuracy 0.91\n",
            "*****Iter 14900*****\n",
            "Train Loss: 0.23801091 Test Loss: 0.33079\n",
            "Test Accuracy 0.8\n",
            "*****Iter 15000*****\n",
            "Train Loss: 0.23566215 Test Loss: 0.31552827\n",
            "Test Accuracy 0.825\n",
            "*****Iter 15100*****\n",
            "Train Loss: 0.266788 Test Loss: 0.26286525\n",
            "Test Accuracy 0.895\n",
            "*****Iter 15200*****\n",
            "Train Loss: 0.26970315 Test Loss: 0.3039177\n",
            "Test Accuracy 0.845\n",
            "*****Iter 15300*****\n",
            "Train Loss: 0.2695066 Test Loss: 0.2691427\n",
            "Test Accuracy 0.895\n",
            "*****Iter 15400*****\n",
            "Train Loss: 0.2772689 Test Loss: 0.26244697\n",
            "Test Accuracy 0.905\n",
            "*****Iter 15500*****\n",
            "Train Loss: 0.2878145 Test Loss: 0.2823298\n",
            "Test Accuracy 0.88\n",
            "*****Iter 15600*****\n",
            "Train Loss: 0.3037126 Test Loss: 0.28801194\n",
            "Test Accuracy 0.855\n",
            "*****Iter 15700*****\n",
            "Train Loss: 0.28768003 Test Loss: 0.27828616\n",
            "Test Accuracy 0.89\n",
            "*****Iter 15800*****\n",
            "Train Loss: 0.3296156 Test Loss: 0.26120436\n",
            "Test Accuracy 0.905\n",
            "*****Iter 15900*****\n",
            "Train Loss: 0.33846325 Test Loss: 0.26952106\n",
            "Test Accuracy 0.9\n",
            "*****Iter 16000*****\n",
            "Train Loss: 0.32168293 Test Loss: 0.27162507\n",
            "Test Accuracy 0.89\n",
            "*****Iter 16100*****\n",
            "Train Loss: 0.26535156 Test Loss: 0.29402223\n",
            "Test Accuracy 0.845\n",
            "*****Iter 16200*****\n",
            "Train Loss: 0.24371499 Test Loss: 0.30328912\n",
            "Test Accuracy 0.84\n",
            "*****Iter 16300*****\n",
            "Train Loss: 0.28776234 Test Loss: 0.2685378\n",
            "Test Accuracy 0.88\n",
            "*****Iter 16400*****\n",
            "Train Loss: 0.271596 Test Loss: 0.24625267\n",
            "Test Accuracy 0.92\n",
            "*****Iter 16500*****\n",
            "Train Loss: 0.23619947 Test Loss: 0.29386806\n",
            "Test Accuracy 0.865\n",
            "*****Iter 16600*****\n",
            "Train Loss: 0.27611798 Test Loss: 0.2624281\n",
            "Test Accuracy 0.905\n",
            "*****Iter 16700*****\n",
            "Train Loss: 0.26661468 Test Loss: 0.28494525\n",
            "Test Accuracy 0.86\n",
            "*****Iter 16800*****\n",
            "Train Loss: 0.21786666 Test Loss: 0.26715404\n",
            "Test Accuracy 0.89\n",
            "*****Iter 16900*****\n",
            "Train Loss: 0.21257816 Test Loss: 0.27702036\n",
            "Test Accuracy 0.9\n",
            "*****Iter 17000*****\n",
            "Train Loss: 0.32908627 Test Loss: 0.28435847\n",
            "Test Accuracy 0.885\n",
            "*****Iter 17100*****\n",
            "Train Loss: 0.22614394 Test Loss: 0.2623286\n",
            "Test Accuracy 0.9\n",
            "*****Iter 17200*****\n",
            "Train Loss: 0.29986462 Test Loss: 0.2445621\n",
            "Test Accuracy 0.935\n",
            "*****Iter 17300*****\n",
            "Train Loss: 0.22619852 Test Loss: 0.25457516\n",
            "Test Accuracy 0.92\n",
            "*****Iter 17400*****\n",
            "Train Loss: 0.27849373 Test Loss: 0.24494255\n",
            "Test Accuracy 0.92\n",
            "*****Iter 17500*****\n",
            "Train Loss: 0.22856826 Test Loss: 0.2446928\n",
            "Test Accuracy 0.93\n",
            "*****Iter 17600*****\n",
            "Train Loss: 0.25596434 Test Loss: 0.26189557\n",
            "Test Accuracy 0.9\n",
            "*****Iter 17700*****\n",
            "Train Loss: 0.2918691 Test Loss: 0.27731428\n",
            "Test Accuracy 0.885\n",
            "*****Iter 17800*****\n",
            "Train Loss: 0.2950943 Test Loss: 0.30875504\n",
            "Test Accuracy 0.835\n",
            "*****Iter 17900*****\n",
            "Train Loss: 0.2538512 Test Loss: 0.2711685\n",
            "Test Accuracy 0.875\n",
            "*****Iter 18000*****\n",
            "Train Loss: 0.234646 Test Loss: 0.28956258\n",
            "Test Accuracy 0.845\n",
            "*****Iter 18100*****\n",
            "Train Loss: 0.26887462 Test Loss: 0.24274608\n",
            "Test Accuracy 0.92\n",
            "*****Iter 18200*****\n",
            "Train Loss: 0.3190564 Test Loss: 0.2963176\n",
            "Test Accuracy 0.855\n",
            "*****Iter 18300*****\n",
            "Train Loss: 0.2634703 Test Loss: 0.27058038\n",
            "Test Accuracy 0.895\n",
            "*****Iter 18400*****\n",
            "Train Loss: 0.23424265 Test Loss: 0.27598882\n",
            "Test Accuracy 0.9\n",
            "*****Iter 18500*****\n",
            "Train Loss: 0.256769 Test Loss: 0.24455903\n",
            "Test Accuracy 0.925\n",
            "*****Iter 18600*****\n",
            "Train Loss: 0.283693 Test Loss: 0.27451882\n",
            "Test Accuracy 0.905\n",
            "*****Iter 18700*****\n",
            "Train Loss: 0.27596712 Test Loss: 0.28832078\n",
            "Test Accuracy 0.86\n",
            "*****Iter 18800*****\n",
            "Train Loss: 0.21254303 Test Loss: 0.29029867\n",
            "Test Accuracy 0.855\n",
            "*****Iter 18900*****\n",
            "Train Loss: 0.33724096 Test Loss: 0.27497917\n",
            "Test Accuracy 0.88\n",
            "*****Iter 19000*****\n",
            "Train Loss: 0.30243638 Test Loss: 0.25078675\n",
            "Test Accuracy 0.915\n",
            "*****Iter 19100*****\n",
            "Train Loss: 0.27889508 Test Loss: 0.28823265\n",
            "Test Accuracy 0.84\n",
            "*****Iter 19200*****\n",
            "Train Loss: 0.20202237 Test Loss: 0.2713457\n",
            "Test Accuracy 0.895\n",
            "*****Iter 19300*****\n",
            "Train Loss: 0.31098887 Test Loss: 0.27283958\n",
            "Test Accuracy 0.885\n",
            "*****Iter 19400*****\n",
            "Train Loss: 0.26373047 Test Loss: 0.27851528\n",
            "Test Accuracy 0.865\n",
            "*****Iter 19500*****\n",
            "Train Loss: 0.26329532 Test Loss: 0.27648246\n",
            "Test Accuracy 0.895\n",
            "*****Iter 19600*****\n",
            "Train Loss: 0.2690197 Test Loss: 0.27277315\n",
            "Test Accuracy 0.89\n",
            "*****Iter 19700*****\n",
            "Train Loss: 0.24558464 Test Loss: 0.26829213\n",
            "Test Accuracy 0.875\n",
            "*****Iter 19800*****\n",
            "Train Loss: 0.2910202 Test Loss: 0.29795235\n",
            "Test Accuracy 0.845\n",
            "*****Iter 19900*****\n",
            "Train Loss: 0.30905217 Test Loss: 0.25212067\n",
            "Test Accuracy 0.92\n",
            "*****Iter 20000*****\n",
            "Train Loss: 0.26599503 Test Loss: 0.2833304\n",
            "Test Accuracy 0.84\n",
            "*****Iter 20100*****\n",
            "Train Loss: 0.28585345 Test Loss: 0.2729528\n",
            "Test Accuracy 0.875\n",
            "*****Iter 20200*****\n",
            "Train Loss: 0.22491057 Test Loss: 0.25693342\n",
            "Test Accuracy 0.915\n",
            "*****Iter 20300*****\n",
            "Train Loss: 0.24738032 Test Loss: 0.30692637\n",
            "Test Accuracy 0.825\n",
            "*****Iter 20400*****\n",
            "Train Loss: 0.33781192 Test Loss: 0.33770996\n",
            "Test Accuracy 0.8\n",
            "*****Iter 20500*****\n",
            "Train Loss: 0.24856302 Test Loss: 0.2851427\n",
            "Test Accuracy 0.87\n",
            "*****Iter 20600*****\n",
            "Train Loss: 0.2505478 Test Loss: 0.27190402\n",
            "Test Accuracy 0.885\n",
            "*****Iter 20700*****\n",
            "Train Loss: 0.23369518 Test Loss: 0.2739041\n",
            "Test Accuracy 0.9\n",
            "*****Iter 20800*****\n",
            "Train Loss: 0.30474496 Test Loss: 0.28851902\n",
            "Test Accuracy 0.865\n",
            "*****Iter 20900*****\n",
            "Train Loss: 0.24491705 Test Loss: 0.27811334\n",
            "Test Accuracy 0.88\n",
            "*****Iter 21000*****\n",
            "Train Loss: 0.3134845 Test Loss: 0.34124127\n",
            "Test Accuracy 0.795\n",
            "*****Iter 21100*****\n",
            "Train Loss: 0.27646673 Test Loss: 0.26541993\n",
            "Test Accuracy 0.905\n",
            "*****Iter 21200*****\n",
            "Train Loss: 0.2623979 Test Loss: 0.29634827\n",
            "Test Accuracy 0.855\n",
            "*****Iter 21300*****\n",
            "Train Loss: 0.29597962 Test Loss: 0.24484837\n",
            "Test Accuracy 0.92\n",
            "*****Iter 21400*****\n",
            "Train Loss: 0.29235396 Test Loss: 0.24834886\n",
            "Test Accuracy 0.92\n",
            "*****Iter 21500*****\n",
            "Train Loss: 0.19085936 Test Loss: 0.2603292\n",
            "Test Accuracy 0.915\n",
            "*****Iter 21600*****\n",
            "Train Loss: 0.28917116 Test Loss: 0.24527578\n",
            "Test Accuracy 0.925\n",
            "*****Iter 21700*****\n",
            "Train Loss: 0.2739592 Test Loss: 0.2691682\n",
            "Test Accuracy 0.895\n",
            "*****Iter 21800*****\n",
            "Train Loss: 0.21370052 Test Loss: 0.24840216\n",
            "Test Accuracy 0.915\n",
            "*****Iter 21900*****\n",
            "Train Loss: 0.25387144 Test Loss: 0.28361163\n",
            "Test Accuracy 0.875\n",
            "*****Iter 22000*****\n",
            "Train Loss: 0.27639437 Test Loss: 0.28729025\n",
            "Test Accuracy 0.87\n",
            "*****Iter 22100*****\n",
            "Train Loss: 0.24190417 Test Loss: 0.28794992\n",
            "Test Accuracy 0.865\n",
            "*****Iter 22200*****\n",
            "Train Loss: 0.22760738 Test Loss: 0.2742445\n",
            "Test Accuracy 0.865\n",
            "*****Iter 22300*****\n",
            "Train Loss: 0.24136925 Test Loss: 0.2497106\n",
            "Test Accuracy 0.915\n",
            "*****Iter 22400*****\n",
            "Train Loss: 0.22247586 Test Loss: 0.2859324\n",
            "Test Accuracy 0.87\n",
            "*****Iter 22500*****\n",
            "Train Loss: 0.2775589 Test Loss: 0.33553967\n",
            "Test Accuracy 0.78\n",
            "*****Iter 22600*****\n",
            "Train Loss: 0.21024445 Test Loss: 0.29739875\n",
            "Test Accuracy 0.84\n",
            "*****Iter 22700*****\n",
            "Train Loss: 0.23602486 Test Loss: 0.25797772\n",
            "Test Accuracy 0.905\n",
            "*****Iter 22800*****\n",
            "Train Loss: 0.23443168 Test Loss: 0.2461468\n",
            "Test Accuracy 0.915\n",
            "*****Iter 22900*****\n",
            "Train Loss: 0.29542053 Test Loss: 0.2948616\n",
            "Test Accuracy 0.85\n",
            "*****Iter 23000*****\n",
            "Train Loss: 0.22636726 Test Loss: 0.26267135\n",
            "Test Accuracy 0.895\n",
            "*****Iter 23100*****\n",
            "Train Loss: 0.23697402 Test Loss: 0.26095706\n",
            "Test Accuracy 0.905\n",
            "*****Iter 23200*****\n",
            "Train Loss: 0.24248987 Test Loss: 0.28237498\n",
            "Test Accuracy 0.87\n",
            "*****Iter 23300*****\n",
            "Train Loss: 0.21644099 Test Loss: 0.24227668\n",
            "Test Accuracy 0.94\n",
            "*****Iter 23400*****\n",
            "Train Loss: 0.3122982 Test Loss: 0.28985897\n",
            "Test Accuracy 0.875\n",
            "*****Iter 23500*****\n",
            "Train Loss: 0.32876238 Test Loss: 0.26564133\n",
            "Test Accuracy 0.895\n",
            "*****Iter 23600*****\n",
            "Train Loss: 0.2876909 Test Loss: 0.2804665\n",
            "Test Accuracy 0.875\n",
            "*****Iter 23700*****\n",
            "Train Loss: 0.21000832 Test Loss: 0.2655149\n",
            "Test Accuracy 0.895\n",
            "*****Iter 23800*****\n",
            "Train Loss: 0.2914104 Test Loss: 0.29486394\n",
            "Test Accuracy 0.86\n",
            "*****Iter 23900*****\n",
            "Train Loss: 0.26092464 Test Loss: 0.27926853\n",
            "Test Accuracy 0.88\n",
            "*****Iter 24000*****\n",
            "Train Loss: 0.24419358 Test Loss: 0.2618395\n",
            "Test Accuracy 0.89\n",
            "*****Iter 24100*****\n",
            "Train Loss: 0.28005916 Test Loss: 0.23023224\n",
            "Test Accuracy 0.965\n",
            "*****Iter 24200*****\n",
            "Train Loss: 0.23119633 Test Loss: 0.2627124\n",
            "Test Accuracy 0.91\n",
            "*****Iter 24300*****\n",
            "Train Loss: 0.2533123 Test Loss: 0.26496944\n",
            "Test Accuracy 0.9\n",
            "*****Iter 24400*****\n",
            "Train Loss: 0.22357789 Test Loss: 0.2438119\n",
            "Test Accuracy 0.94\n",
            "*****Iter 24500*****\n",
            "Train Loss: 0.26008773 Test Loss: 0.2777127\n",
            "Test Accuracy 0.86\n",
            "*****Iter 24600*****\n",
            "Train Loss: 0.27792794 Test Loss: 0.26597932\n",
            "Test Accuracy 0.88\n",
            "*****Iter 24700*****\n",
            "Train Loss: 0.24951483 Test Loss: 0.23704347\n",
            "Test Accuracy 0.945\n",
            "*****Iter 24800*****\n",
            "Train Loss: 0.27145252 Test Loss: 0.27549222\n",
            "Test Accuracy 0.89\n",
            "*****Iter 24900*****\n",
            "Train Loss: 0.2615981 Test Loss: 0.24474275\n",
            "Test Accuracy 0.92\n",
            "*****Iter 25000*****\n",
            "Train Loss: 0.21735865 Test Loss: 0.29433268\n",
            "Test Accuracy 0.845\n",
            "K: 1, N: 3\n",
            "*****Iter 100*****\n",
            "Train Loss: 0.8067042 Test Loss: 0.8329435\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 200*****\n",
            "Train Loss: 0.7523844 Test Loss: 0.76055217\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 300*****\n",
            "Train Loss: 0.75552964 Test Loss: 0.75575835\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 400*****\n",
            "Train Loss: 0.75523394 Test Loss: 0.74590635\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 500*****\n",
            "Train Loss: 0.75425905 Test Loss: 0.7497086\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 600*****\n",
            "Train Loss: 0.75233316 Test Loss: 0.75458187\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 700*****\n",
            "Train Loss: 0.7525797 Test Loss: 0.75303364\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 800*****\n",
            "Train Loss: 0.7492792 Test Loss: 0.75176126\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 900*****\n",
            "Train Loss: 0.7547652 Test Loss: 0.75060457\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1000*****\n",
            "Train Loss: 0.7724182 Test Loss: 0.7542287\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1100*****\n",
            "Train Loss: 0.7551613 Test Loss: 0.75326526\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1200*****\n",
            "Train Loss: 0.7505131 Test Loss: 0.7393322\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1300*****\n",
            "Train Loss: 0.7629132 Test Loss: 0.7529615\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1400*****\n",
            "Train Loss: 0.7207671 Test Loss: 0.7445918\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1500*****\n",
            "Train Loss: 0.745876 Test Loss: 0.7359616\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1600*****\n",
            "Train Loss: 0.7288692 Test Loss: 0.73686963\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1700*****\n",
            "Train Loss: 0.75740784 Test Loss: 0.7373074\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 1800*****\n",
            "Train Loss: 0.7220548 Test Loss: 0.73179567\n",
            "Test Accuracy 0.33\n",
            "*****Iter 1900*****\n",
            "Train Loss: 0.7245626 Test Loss: 0.7351208\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 2000*****\n",
            "Train Loss: 0.73658705 Test Loss: 0.7432199\n",
            "Test Accuracy 0.34333333\n",
            "*****Iter 2100*****\n",
            "Train Loss: 0.7241533 Test Loss: 0.7453767\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 2200*****\n",
            "Train Loss: 0.71952945 Test Loss: 0.73285764\n",
            "Test Accuracy 0.31\n",
            "*****Iter 2300*****\n",
            "Train Loss: 0.7248595 Test Loss: 0.7552357\n",
            "Test Accuracy 0.33666667\n",
            "*****Iter 2400*****\n",
            "Train Loss: 0.7209606 Test Loss: 0.73686194\n",
            "Test Accuracy 0.32\n",
            "*****Iter 2500*****\n",
            "Train Loss: 0.739736 Test Loss: 0.74541175\n",
            "Test Accuracy 0.41333333\n",
            "*****Iter 2600*****\n",
            "Train Loss: 0.7234705 Test Loss: 0.73784876\n",
            "Test Accuracy 0.30333334\n",
            "*****Iter 2700*****\n",
            "Train Loss: 0.7368447 Test Loss: 0.72915256\n",
            "Test Accuracy 0.24333334\n",
            "*****Iter 2800*****\n",
            "Train Loss: 0.7324427 Test Loss: 0.73037136\n",
            "Test Accuracy 0.3\n",
            "*****Iter 2900*****\n",
            "Train Loss: 0.7410663 Test Loss: 0.730171\n",
            "Test Accuracy 0.27333334\n",
            "*****Iter 3000*****\n",
            "Train Loss: 0.71770114 Test Loss: 0.74099964\n",
            "Test Accuracy 0.24333334\n",
            "*****Iter 3100*****\n",
            "Train Loss: 0.712173 Test Loss: 0.72852904\n",
            "Test Accuracy 0.26666668\n",
            "*****Iter 3200*****\n",
            "Train Loss: 0.74168754 Test Loss: 0.7204609\n",
            "Test Accuracy 0.4\n",
            "*****Iter 3300*****\n",
            "Train Loss: 0.73203593 Test Loss: 0.7266239\n",
            "Test Accuracy 0.33666667\n",
            "*****Iter 3400*****\n",
            "Train Loss: 0.7310727 Test Loss: 0.73405653\n",
            "Test Accuracy 0.39\n",
            "*****Iter 3500*****\n",
            "Train Loss: 0.74812603 Test Loss: 0.72807467\n",
            "Test Accuracy 0.30333334\n",
            "*****Iter 3600*****\n",
            "Train Loss: 0.71382 Test Loss: 0.71464556\n",
            "Test Accuracy 0.34333333\n",
            "*****Iter 3700*****\n",
            "Train Loss: 0.72431135 Test Loss: 0.7041984\n",
            "Test Accuracy 0.52\n",
            "*****Iter 3800*****\n",
            "Train Loss: 0.7316708 Test Loss: 0.734057\n",
            "Test Accuracy 0.4\n",
            "*****Iter 3900*****\n",
            "Train Loss: 0.69388217 Test Loss: 0.7212318\n",
            "Test Accuracy 0.38\n",
            "*****Iter 4000*****\n",
            "Train Loss: 0.72141916 Test Loss: 0.7072829\n",
            "Test Accuracy 0.35666665\n",
            "*****Iter 4100*****\n",
            "Train Loss: 0.70128727 Test Loss: 0.6738994\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 4200*****\n",
            "Train Loss: 0.6832738 Test Loss: 0.71443063\n",
            "Test Accuracy 0.40333334\n",
            "*****Iter 4300*****\n",
            "Train Loss: 0.71229815 Test Loss: 0.71475583\n",
            "Test Accuracy 0.39\n",
            "*****Iter 4400*****\n",
            "Train Loss: 0.6760786 Test Loss: 0.7214812\n",
            "Test Accuracy 0.37\n",
            "*****Iter 4500*****\n",
            "Train Loss: 0.6967214 Test Loss: 0.69173104\n",
            "Test Accuracy 0.40666667\n",
            "*****Iter 4600*****\n",
            "Train Loss: 0.7211838 Test Loss: 0.702751\n",
            "Test Accuracy 0.42\n",
            "*****Iter 4700*****\n",
            "Train Loss: 0.68386126 Test Loss: 0.6797981\n",
            "Test Accuracy 0.46333334\n",
            "*****Iter 4800*****\n",
            "Train Loss: 0.69657665 Test Loss: 0.701319\n",
            "Test Accuracy 0.4\n",
            "*****Iter 4900*****\n",
            "Train Loss: 0.67392594 Test Loss: 0.6626982\n",
            "Test Accuracy 0.44\n",
            "*****Iter 5000*****\n",
            "Train Loss: 0.66256386 Test Loss: 0.6809455\n",
            "Test Accuracy 0.40666667\n",
            "*****Iter 5100*****\n",
            "Train Loss: 0.66219014 Test Loss: 0.6578283\n",
            "Test Accuracy 0.40666667\n",
            "*****Iter 5200*****\n",
            "Train Loss: 0.69925946 Test Loss: 0.65718895\n",
            "Test Accuracy 0.43333334\n",
            "*****Iter 5300*****\n",
            "Train Loss: 0.65936714 Test Loss: 0.6805754\n",
            "Test Accuracy 0.39666668\n",
            "*****Iter 5400*****\n",
            "Train Loss: 0.656074 Test Loss: 0.6679378\n",
            "Test Accuracy 0.42333335\n",
            "*****Iter 5500*****\n",
            "Train Loss: 0.63618845 Test Loss: 0.6747282\n",
            "Test Accuracy 0.38666666\n",
            "*****Iter 5600*****\n",
            "Train Loss: 0.67118883 Test Loss: 0.6887316\n",
            "Test Accuracy 0.39\n",
            "*****Iter 5700*****\n",
            "Train Loss: 0.6601824 Test Loss: 0.6743979\n",
            "Test Accuracy 0.43\n",
            "*****Iter 5800*****\n",
            "Train Loss: 0.6912119 Test Loss: 0.66353136\n",
            "Test Accuracy 0.44\n",
            "*****Iter 5900*****\n",
            "Train Loss: 0.66889507 Test Loss: 0.674173\n",
            "Test Accuracy 0.42666668\n",
            "*****Iter 6000*****\n",
            "Train Loss: 0.61951894 Test Loss: 0.6880775\n",
            "Test Accuracy 0.33333334\n",
            "*****Iter 6100*****\n",
            "Train Loss: 0.6865268 Test Loss: 0.69698346\n",
            "Test Accuracy 0.37333333\n",
            "*****Iter 6200*****\n",
            "Train Loss: 0.67591065 Test Loss: 0.6972696\n",
            "Test Accuracy 0.36666667\n",
            "*****Iter 6300*****\n",
            "Train Loss: 0.6764706 Test Loss: 0.66588867\n",
            "Test Accuracy 0.39666668\n",
            "*****Iter 6400*****\n",
            "Train Loss: 0.6754295 Test Loss: 0.6621608\n",
            "Test Accuracy 0.42666668\n",
            "*****Iter 6500*****\n",
            "Train Loss: 0.66684145 Test Loss: 0.6812184\n",
            "Test Accuracy 0.36333334\n",
            "*****Iter 6600*****\n",
            "Train Loss: 0.69642377 Test Loss: 0.6699513\n",
            "Test Accuracy 0.41666666\n",
            "*****Iter 6700*****\n",
            "Train Loss: 0.64569396 Test Loss: 0.6911179\n",
            "Test Accuracy 0.38333333\n",
            "*****Iter 6800*****\n",
            "Train Loss: 0.68787926 Test Loss: 0.6628726\n",
            "Test Accuracy 0.43\n",
            "*****Iter 6900*****\n",
            "Train Loss: 0.6678373 Test Loss: 0.6800158\n",
            "Test Accuracy 0.41\n",
            "*****Iter 7000*****\n",
            "Train Loss: 0.6809271 Test Loss: 0.6639867\n",
            "Test Accuracy 0.38666666\n",
            "*****Iter 7100*****\n",
            "Train Loss: 0.650771 Test Loss: 0.6597017\n",
            "Test Accuracy 0.44\n",
            "*****Iter 7200*****\n",
            "Train Loss: 0.6608031 Test Loss: 0.676364\n",
            "Test Accuracy 0.39\n",
            "*****Iter 7300*****\n",
            "Train Loss: 0.6247135 Test Loss: 0.6655745\n",
            "Test Accuracy 0.41333333\n",
            "*****Iter 7400*****\n",
            "Train Loss: 0.6676579 Test Loss: 0.6516805\n",
            "Test Accuracy 0.44\n",
            "*****Iter 7500*****\n",
            "Train Loss: 0.70481515 Test Loss: 0.65864587\n",
            "Test Accuracy 0.4\n",
            "*****Iter 7600*****\n",
            "Train Loss: 0.6777281 Test Loss: 0.6793543\n",
            "Test Accuracy 0.41333333\n",
            "*****Iter 7700*****\n",
            "Train Loss: 0.67173916 Test Loss: 0.66652185\n",
            "Test Accuracy 0.40333334\n",
            "*****Iter 7800*****\n",
            "Train Loss: 0.65360314 Test Loss: 0.68126166\n",
            "Test Accuracy 0.39666668\n",
            "*****Iter 7900*****\n",
            "Train Loss: 0.6282 Test Loss: 0.6572108\n",
            "Test Accuracy 0.43666667\n",
            "*****Iter 8000*****\n",
            "Train Loss: 0.66018325 Test Loss: 0.653627\n",
            "Test Accuracy 0.42\n",
            "*****Iter 8100*****\n",
            "Train Loss: 0.67027193 Test Loss: 0.678359\n",
            "Test Accuracy 0.40333334\n",
            "*****Iter 8200*****\n",
            "Train Loss: 0.67004377 Test Loss: 0.66317225\n",
            "Test Accuracy 0.45666668\n",
            "*****Iter 8300*****\n",
            "Train Loss: 0.718949 Test Loss: 0.67677915\n",
            "Test Accuracy 0.42\n",
            "*****Iter 8400*****\n",
            "Train Loss: 0.66743773 Test Loss: 0.67619044\n",
            "Test Accuracy 0.44\n",
            "*****Iter 8500*****\n",
            "Train Loss: 0.63117915 Test Loss: 0.6608252\n",
            "Test Accuracy 0.39666668\n",
            "*****Iter 8600*****\n",
            "Train Loss: 0.6522979 Test Loss: 0.66228396\n",
            "Test Accuracy 0.39\n",
            "*****Iter 8700*****\n",
            "Train Loss: 0.6819701 Test Loss: 0.672307\n",
            "Test Accuracy 0.39333335\n",
            "*****Iter 8800*****\n",
            "Train Loss: 0.6562347 Test Loss: 0.65761995\n",
            "Test Accuracy 0.43333334\n",
            "*****Iter 8900*****\n",
            "Train Loss: 0.6610671 Test Loss: 0.6677256\n",
            "Test Accuracy 0.43666667\n",
            "*****Iter 9000*****\n",
            "Train Loss: 0.6996084 Test Loss: 0.6403543\n",
            "Test Accuracy 0.45666668\n",
            "*****Iter 9100*****\n",
            "Train Loss: 0.6418287 Test Loss: 0.6533995\n",
            "Test Accuracy 0.46333334\n",
            "*****Iter 9200*****\n",
            "Train Loss: 0.65457773 Test Loss: 0.6823408\n",
            "Test Accuracy 0.39666668\n",
            "*****Iter 9300*****\n",
            "Train Loss: 0.6338191 Test Loss: 0.67089295\n",
            "Test Accuracy 0.38666666\n",
            "*****Iter 9400*****\n",
            "Train Loss: 0.6512807 Test Loss: 0.65460986\n",
            "Test Accuracy 0.40666667\n",
            "*****Iter 9500*****\n",
            "Train Loss: 0.6865854 Test Loss: 0.68104225\n",
            "Test Accuracy 0.41\n",
            "*****Iter 9600*****\n",
            "Train Loss: 0.6575435 Test Loss: 0.6640619\n",
            "Test Accuracy 0.45666668\n",
            "*****Iter 9700*****\n",
            "Train Loss: 0.66377133 Test Loss: 0.68080467\n",
            "Test Accuracy 0.38\n",
            "*****Iter 9800*****\n",
            "Train Loss: 0.68152267 Test Loss: 0.7056798\n",
            "Test Accuracy 0.35\n",
            "*****Iter 9900*****\n",
            "Train Loss: 0.6696484 Test Loss: 0.6701081\n",
            "Test Accuracy 0.42666668\n",
            "*****Iter 10000*****\n",
            "Train Loss: 0.6034234 Test Loss: 0.65740186\n",
            "Test Accuracy 0.48666668\n",
            "*****Iter 10100*****\n",
            "Train Loss: 0.631815 Test Loss: 0.65996534\n",
            "Test Accuracy 0.42\n",
            "*****Iter 10200*****\n",
            "Train Loss: 0.65109223 Test Loss: 0.69733584\n",
            "Test Accuracy 0.4\n",
            "*****Iter 10300*****\n",
            "Train Loss: 0.6595288 Test Loss: 0.6670593\n",
            "Test Accuracy 0.4\n",
            "*****Iter 10400*****\n",
            "Train Loss: 0.6229027 Test Loss: 0.6583421\n",
            "Test Accuracy 0.43333334\n",
            "*****Iter 10500*****\n",
            "Train Loss: 0.6441242 Test Loss: 0.65939105\n",
            "Test Accuracy 0.43333334\n",
            "*****Iter 10600*****\n",
            "Train Loss: 0.6607888 Test Loss: 0.6770462\n",
            "Test Accuracy 0.43666667\n",
            "*****Iter 10700*****\n",
            "Train Loss: 0.69901615 Test Loss: 0.6527996\n",
            "Test Accuracy 0.48333332\n",
            "*****Iter 10800*****\n",
            "Train Loss: 0.64561063 Test Loss: 0.65373594\n",
            "Test Accuracy 0.52\n",
            "*****Iter 10900*****\n",
            "Train Loss: 0.6922903 Test Loss: 0.668027\n",
            "Test Accuracy 0.44333333\n",
            "*****Iter 11000*****\n",
            "Train Loss: 0.6830845 Test Loss: 0.66994286\n",
            "Test Accuracy 0.44\n",
            "*****Iter 11100*****\n",
            "Train Loss: 0.65675724 Test Loss: 0.6592371\n",
            "Test Accuracy 0.45\n",
            "*****Iter 11200*****\n",
            "Train Loss: 0.6781753 Test Loss: 0.6671047\n",
            "Test Accuracy 0.49666667\n",
            "*****Iter 11300*****\n",
            "Train Loss: 0.664836 Test Loss: 0.6634001\n",
            "Test Accuracy 0.51666665\n",
            "*****Iter 11400*****\n",
            "Train Loss: 0.6642997 Test Loss: 0.6655473\n",
            "Test Accuracy 0.47\n",
            "*****Iter 11500*****\n",
            "Train Loss: 0.67383003 Test Loss: 0.6814892\n",
            "Test Accuracy 0.46666667\n",
            "*****Iter 11600*****\n",
            "Train Loss: 0.6873253 Test Loss: 0.6561755\n",
            "Test Accuracy 0.5\n",
            "*****Iter 11700*****\n",
            "Train Loss: 0.6937394 Test Loss: 0.66592\n",
            "Test Accuracy 0.47\n",
            "*****Iter 11800*****\n",
            "Train Loss: 0.6191402 Test Loss: 0.63738215\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 11900*****\n",
            "Train Loss: 0.6425379 Test Loss: 0.64894533\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 12000*****\n",
            "Train Loss: 0.63548774 Test Loss: 0.6330441\n",
            "Test Accuracy 0.57666665\n",
            "*****Iter 12100*****\n",
            "Train Loss: 0.6284625 Test Loss: 0.641865\n",
            "Test Accuracy 0.54\n",
            "*****Iter 12200*****\n",
            "Train Loss: 0.6392916 Test Loss: 0.66576916\n",
            "Test Accuracy 0.49\n",
            "*****Iter 12300*****\n",
            "Train Loss: 0.6469907 Test Loss: 0.6422325\n",
            "Test Accuracy 0.49\n",
            "*****Iter 12400*****\n",
            "Train Loss: 0.6604971 Test Loss: 0.6382588\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 12500*****\n",
            "Train Loss: 0.66620785 Test Loss: 0.6507118\n",
            "Test Accuracy 0.5133333\n",
            "*****Iter 12600*****\n",
            "Train Loss: 0.60527635 Test Loss: 0.64027965\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 12700*****\n",
            "Train Loss: 0.6297565 Test Loss: 0.63856\n",
            "Test Accuracy 0.5133333\n",
            "*****Iter 12800*****\n",
            "Train Loss: 0.6453126 Test Loss: 0.66149\n",
            "Test Accuracy 0.46\n",
            "*****Iter 12900*****\n",
            "Train Loss: 0.62896943 Test Loss: 0.6479592\n",
            "Test Accuracy 0.48333332\n",
            "*****Iter 13000*****\n",
            "Train Loss: 0.63705677 Test Loss: 0.6568413\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 13100*****\n",
            "Train Loss: 0.6346714 Test Loss: 0.6693376\n",
            "Test Accuracy 0.48333332\n",
            "*****Iter 13200*****\n",
            "Train Loss: 0.643414 Test Loss: 0.62572056\n",
            "Test Accuracy 0.56666666\n",
            "*****Iter 13300*****\n",
            "Train Loss: 0.700295 Test Loss: 0.65206665\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 13400*****\n",
            "Train Loss: 0.6565905 Test Loss: 0.6301826\n",
            "Test Accuracy 0.54333335\n",
            "*****Iter 13500*****\n",
            "Train Loss: 0.65689933 Test Loss: 0.6447534\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 13600*****\n",
            "Train Loss: 0.6292064 Test Loss: 0.64187986\n",
            "Test Accuracy 0.54333335\n",
            "*****Iter 13700*****\n",
            "Train Loss: 0.63288367 Test Loss: 0.65354455\n",
            "Test Accuracy 0.49\n",
            "*****Iter 13800*****\n",
            "Train Loss: 0.6472257 Test Loss: 0.6249811\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 13900*****\n",
            "Train Loss: 0.632334 Test Loss: 0.64659417\n",
            "Test Accuracy 0.5\n",
            "*****Iter 14000*****\n",
            "Train Loss: 0.62650084 Test Loss: 0.64165306\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 14100*****\n",
            "Train Loss: 0.63707227 Test Loss: 0.6456293\n",
            "Test Accuracy 0.5\n",
            "*****Iter 14200*****\n",
            "Train Loss: 0.6348143 Test Loss: 0.6412557\n",
            "Test Accuracy 0.53\n",
            "*****Iter 14300*****\n",
            "Train Loss: 0.61617845 Test Loss: 0.64240766\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 14400*****\n",
            "Train Loss: 0.6582257 Test Loss: 0.6397738\n",
            "Test Accuracy 0.5133333\n",
            "*****Iter 14500*****\n",
            "Train Loss: 0.62807006 Test Loss: 0.6410281\n",
            "Test Accuracy 0.50666666\n",
            "*****Iter 14600*****\n",
            "Train Loss: 0.61794424 Test Loss: 0.6501676\n",
            "Test Accuracy 0.52\n",
            "*****Iter 14700*****\n",
            "Train Loss: 0.646388 Test Loss: 0.6375174\n",
            "Test Accuracy 0.50333333\n",
            "*****Iter 14800*****\n",
            "Train Loss: 0.62228876 Test Loss: 0.63938856\n",
            "Test Accuracy 0.56\n",
            "*****Iter 14900*****\n",
            "Train Loss: 0.61263114 Test Loss: 0.6326006\n",
            "Test Accuracy 0.55\n",
            "*****Iter 15000*****\n",
            "Train Loss: 0.62117743 Test Loss: 0.6366031\n",
            "Test Accuracy 0.53\n",
            "*****Iter 15100*****\n",
            "Train Loss: 0.62946695 Test Loss: 0.6515655\n",
            "Test Accuracy 0.49666667\n",
            "*****Iter 15200*****\n",
            "Train Loss: 0.6495983 Test Loss: 0.6353905\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 15300*****\n",
            "Train Loss: 0.6040868 Test Loss: 0.62711376\n",
            "Test Accuracy 0.5566667\n",
            "*****Iter 15400*****\n",
            "Train Loss: 0.6388547 Test Loss: 0.6372276\n",
            "Test Accuracy 0.52\n",
            "*****Iter 15500*****\n",
            "Train Loss: 0.620614 Test Loss: 0.64695394\n",
            "Test Accuracy 0.53\n",
            "*****Iter 15600*****\n",
            "Train Loss: 0.623354 Test Loss: 0.6360304\n",
            "Test Accuracy 0.5366667\n",
            "*****Iter 15700*****\n",
            "Train Loss: 0.60957783 Test Loss: 0.6336046\n",
            "Test Accuracy 0.52\n",
            "*****Iter 15800*****\n",
            "Train Loss: 0.6631234 Test Loss: 0.64214516\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 15900*****\n",
            "Train Loss: 0.6239647 Test Loss: 0.61298966\n",
            "Test Accuracy 0.5466667\n",
            "*****Iter 16000*****\n",
            "Train Loss: 0.64380413 Test Loss: 0.627687\n",
            "Test Accuracy 0.54333335\n",
            "*****Iter 16100*****\n",
            "Train Loss: 0.6170087 Test Loss: 0.63375604\n",
            "Test Accuracy 0.5366667\n",
            "*****Iter 16200*****\n",
            "Train Loss: 0.61804223 Test Loss: 0.63493884\n",
            "Test Accuracy 0.53\n",
            "*****Iter 16300*****\n",
            "Train Loss: 0.6112823 Test Loss: 0.6435046\n",
            "Test Accuracy 0.5133333\n",
            "*****Iter 16400*****\n",
            "Train Loss: 0.6029938 Test Loss: 0.62750703\n",
            "Test Accuracy 0.55333334\n",
            "*****Iter 16500*****\n",
            "Train Loss: 0.6259577 Test Loss: 0.62515026\n",
            "Test Accuracy 0.5466667\n",
            "*****Iter 16600*****\n",
            "Train Loss: 0.60643077 Test Loss: 0.64901245\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 16700*****\n",
            "Train Loss: 0.62046653 Test Loss: 0.6312121\n",
            "Test Accuracy 0.5566667\n",
            "*****Iter 16800*****\n",
            "Train Loss: 0.6318599 Test Loss: 0.6420359\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 16900*****\n",
            "Train Loss: 0.6546295 Test Loss: 0.6277683\n",
            "Test Accuracy 0.51666665\n",
            "*****Iter 17000*****\n",
            "Train Loss: 0.6326361 Test Loss: 0.6393399\n",
            "Test Accuracy 0.51666665\n",
            "*****Iter 17100*****\n",
            "Train Loss: 0.64933276 Test Loss: 0.62132525\n",
            "Test Accuracy 0.53\n",
            "*****Iter 17200*****\n",
            "Train Loss: 0.62406033 Test Loss: 0.62021583\n",
            "Test Accuracy 0.5733333\n",
            "*****Iter 17300*****\n",
            "Train Loss: 0.6102805 Test Loss: 0.60887206\n",
            "Test Accuracy 0.5966667\n",
            "*****Iter 17400*****\n",
            "Train Loss: 0.6571539 Test Loss: 0.6565398\n",
            "Test Accuracy 0.49333334\n",
            "*****Iter 17500*****\n",
            "Train Loss: 0.6355023 Test Loss: 0.6338429\n",
            "Test Accuracy 0.49\n",
            "*****Iter 17600*****\n",
            "Train Loss: 0.578532 Test Loss: 0.61851734\n",
            "Test Accuracy 0.55333334\n",
            "*****Iter 17700*****\n",
            "Train Loss: 0.62878317 Test Loss: 0.62786454\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 17800*****\n",
            "Train Loss: 0.60232717 Test Loss: 0.6226605\n",
            "Test Accuracy 0.51666665\n",
            "*****Iter 17900*****\n",
            "Train Loss: 0.6244777 Test Loss: 0.62110376\n",
            "Test Accuracy 0.57666665\n",
            "*****Iter 18000*****\n",
            "Train Loss: 0.58270216 Test Loss: 0.6484489\n",
            "Test Accuracy 0.51\n",
            "*****Iter 18100*****\n",
            "Train Loss: 0.5977356 Test Loss: 0.61850286\n",
            "Test Accuracy 0.5566667\n",
            "*****Iter 18200*****\n",
            "Train Loss: 0.5972586 Test Loss: 0.61024356\n",
            "Test Accuracy 0.5366667\n",
            "*****Iter 18300*****\n",
            "Train Loss: 0.6604505 Test Loss: 0.6328868\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 18400*****\n",
            "Train Loss: 0.6037567 Test Loss: 0.61865395\n",
            "Test Accuracy 0.56\n",
            "*****Iter 18500*****\n",
            "Train Loss: 0.59760594 Test Loss: 0.6428717\n",
            "Test Accuracy 0.51666665\n",
            "*****Iter 18600*****\n",
            "Train Loss: 0.5768898 Test Loss: 0.6282014\n",
            "Test Accuracy 0.56\n",
            "*****Iter 18700*****\n",
            "Train Loss: 0.6463235 Test Loss: 0.6300047\n",
            "Test Accuracy 0.54333335\n",
            "*****Iter 18800*****\n",
            "Train Loss: 0.609049 Test Loss: 0.6160889\n",
            "Test Accuracy 0.5833333\n",
            "*****Iter 18900*****\n",
            "Train Loss: 0.6270419 Test Loss: 0.63427806\n",
            "Test Accuracy 0.51\n",
            "*****Iter 19000*****\n",
            "Train Loss: 0.62363744 Test Loss: 0.6076474\n",
            "Test Accuracy 0.5733333\n",
            "*****Iter 19100*****\n",
            "Train Loss: 0.6197858 Test Loss: 0.62866706\n",
            "Test Accuracy 0.5466667\n",
            "*****Iter 19200*****\n",
            "Train Loss: 0.6234481 Test Loss: 0.6342115\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 19300*****\n",
            "Train Loss: 0.6016918 Test Loss: 0.62731487\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 19400*****\n",
            "Train Loss: 0.5829518 Test Loss: 0.64217013\n",
            "Test Accuracy 0.54333335\n",
            "*****Iter 19500*****\n",
            "Train Loss: 0.62211204 Test Loss: 0.63136965\n",
            "Test Accuracy 0.54\n",
            "*****Iter 19600*****\n",
            "Train Loss: 0.6211942 Test Loss: 0.61660194\n",
            "Test Accuracy 0.55333334\n",
            "*****Iter 19700*****\n",
            "Train Loss: 0.5996413 Test Loss: 0.6109364\n",
            "Test Accuracy 0.5733333\n",
            "*****Iter 19800*****\n",
            "Train Loss: 0.6149239 Test Loss: 0.63327247\n",
            "Test Accuracy 0.5466667\n",
            "*****Iter 19900*****\n",
            "Train Loss: 0.64133006 Test Loss: 0.6031676\n",
            "Test Accuracy 0.56666666\n",
            "*****Iter 20000*****\n",
            "Train Loss: 0.6127925 Test Loss: 0.63347715\n",
            "Test Accuracy 0.52\n",
            "*****Iter 20100*****\n",
            "Train Loss: 0.63073164 Test Loss: 0.63122123\n",
            "Test Accuracy 0.54\n",
            "*****Iter 20200*****\n",
            "Train Loss: 0.6261856 Test Loss: 0.621955\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 20300*****\n",
            "Train Loss: 0.60502636 Test Loss: 0.59042436\n",
            "Test Accuracy 0.6\n",
            "*****Iter 20400*****\n",
            "Train Loss: 0.628308 Test Loss: 0.6235852\n",
            "Test Accuracy 0.56333333\n",
            "*****Iter 20500*****\n",
            "Train Loss: 0.62066823 Test Loss: 0.64125377\n",
            "Test Accuracy 0.47\n",
            "*****Iter 20600*****\n",
            "Train Loss: 0.601066 Test Loss: 0.6137763\n",
            "Test Accuracy 0.5366667\n",
            "*****Iter 20700*****\n",
            "Train Loss: 0.6402492 Test Loss: 0.6264522\n",
            "Test Accuracy 0.55333334\n",
            "*****Iter 20800*****\n",
            "Train Loss: 0.60428125 Test Loss: 0.60694313\n",
            "Test Accuracy 0.53\n",
            "*****Iter 20900*****\n",
            "Train Loss: 0.6021416 Test Loss: 0.63341624\n",
            "Test Accuracy 0.52\n",
            "*****Iter 21000*****\n",
            "Train Loss: 0.60808486 Test Loss: 0.62385404\n",
            "Test Accuracy 0.51666665\n",
            "*****Iter 21100*****\n",
            "Train Loss: 0.6232025 Test Loss: 0.6309441\n",
            "Test Accuracy 0.53\n",
            "*****Iter 21200*****\n",
            "Train Loss: 0.62177277 Test Loss: 0.6369218\n",
            "Test Accuracy 0.5133333\n",
            "*****Iter 21300*****\n",
            "Train Loss: 0.6322162 Test Loss: 0.61949044\n",
            "Test Accuracy 0.54\n",
            "*****Iter 21400*****\n",
            "Train Loss: 0.609466 Test Loss: 0.6098787\n",
            "Test Accuracy 0.55333334\n",
            "*****Iter 21500*****\n",
            "Train Loss: 0.6142697 Test Loss: 0.6130373\n",
            "Test Accuracy 0.57\n",
            "*****Iter 21600*****\n",
            "Train Loss: 0.61396414 Test Loss: 0.62399215\n",
            "Test Accuracy 0.55333334\n",
            "*****Iter 21700*****\n",
            "Train Loss: 0.6168049 Test Loss: 0.61112744\n",
            "Test Accuracy 0.53\n",
            "*****Iter 21800*****\n",
            "Train Loss: 0.61522335 Test Loss: 0.6092454\n",
            "Test Accuracy 0.54\n",
            "*****Iter 21900*****\n",
            "Train Loss: 0.6274385 Test Loss: 0.6057014\n",
            "Test Accuracy 0.57666665\n",
            "*****Iter 22000*****\n",
            "Train Loss: 0.5971491 Test Loss: 0.5902681\n",
            "Test Accuracy 0.5733333\n",
            "*****Iter 22100*****\n",
            "Train Loss: 0.6295131 Test Loss: 0.60592276\n",
            "Test Accuracy 0.5566667\n",
            "*****Iter 22200*****\n",
            "Train Loss: 0.5914852 Test Loss: 0.61785585\n",
            "Test Accuracy 0.53\n",
            "*****Iter 22300*****\n",
            "Train Loss: 0.6221152 Test Loss: 0.61323327\n",
            "Test Accuracy 0.56\n",
            "*****Iter 22400*****\n",
            "Train Loss: 0.58395267 Test Loss: 0.6219855\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 22500*****\n",
            "Train Loss: 0.5918546 Test Loss: 0.61584806\n",
            "Test Accuracy 0.50666666\n",
            "*****Iter 22600*****\n",
            "Train Loss: 0.59790534 Test Loss: 0.5979613\n",
            "Test Accuracy 0.59\n",
            "*****Iter 22700*****\n",
            "Train Loss: 0.6502961 Test Loss: 0.6085283\n",
            "Test Accuracy 0.51666665\n",
            "*****Iter 22800*****\n",
            "Train Loss: 0.5673875 Test Loss: 0.62954366\n",
            "Test Accuracy 0.54333335\n",
            "*****Iter 22900*****\n",
            "Train Loss: 0.63532406 Test Loss: 0.60662895\n",
            "Test Accuracy 0.55333334\n",
            "*****Iter 23000*****\n",
            "Train Loss: 0.608954 Test Loss: 0.6060162\n",
            "Test Accuracy 0.5566667\n",
            "*****Iter 23100*****\n",
            "Train Loss: 0.65743846 Test Loss: 0.6290936\n",
            "Test Accuracy 0.50666666\n",
            "*****Iter 23200*****\n",
            "Train Loss: 0.60044056 Test Loss: 0.6161302\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 23300*****\n",
            "Train Loss: 0.59756213 Test Loss: 0.6159624\n",
            "Test Accuracy 0.53\n",
            "*****Iter 23400*****\n",
            "Train Loss: 0.57893586 Test Loss: 0.62142473\n",
            "Test Accuracy 0.53\n",
            "*****Iter 23500*****\n",
            "Train Loss: 0.6155405 Test Loss: 0.61916786\n",
            "Test Accuracy 0.53333336\n",
            "*****Iter 23600*****\n",
            "Train Loss: 0.58304495 Test Loss: 0.6115599\n",
            "Test Accuracy 0.5366667\n",
            "*****Iter 23700*****\n",
            "Train Loss: 0.5912322 Test Loss: 0.62014335\n",
            "Test Accuracy 0.53\n",
            "*****Iter 23800*****\n",
            "Train Loss: 0.60001606 Test Loss: 0.61926323\n",
            "Test Accuracy 0.5233333\n",
            "*****Iter 23900*****\n",
            "Train Loss: 0.5921659 Test Loss: 0.62936676\n",
            "Test Accuracy 0.52\n",
            "*****Iter 24000*****\n",
            "Train Loss: 0.61340296 Test Loss: 0.5956889\n",
            "Test Accuracy 0.57666665\n",
            "*****Iter 24100*****\n",
            "Train Loss: 0.58251673 Test Loss: 0.60002965\n",
            "Test Accuracy 0.57666665\n",
            "*****Iter 24200*****\n",
            "Train Loss: 0.5695739 Test Loss: 0.6114982\n",
            "Test Accuracy 0.5566667\n",
            "*****Iter 24300*****\n",
            "Train Loss: 0.5980975 Test Loss: 0.5991879\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 24400*****\n",
            "Train Loss: 0.61163074 Test Loss: 0.62567174\n",
            "Test Accuracy 0.50666666\n",
            "*****Iter 24500*****\n",
            "Train Loss: 0.58103514 Test Loss: 0.60967106\n",
            "Test Accuracy 0.5566667\n",
            "*****Iter 24600*****\n",
            "Train Loss: 0.6123207 Test Loss: 0.5965547\n",
            "Test Accuracy 0.5466667\n",
            "*****Iter 24700*****\n",
            "Train Loss: 0.66411334 Test Loss: 0.6279787\n",
            "Test Accuracy 0.52\n",
            "*****Iter 24800*****\n",
            "Train Loss: 0.59927803 Test Loss: 0.6113574\n",
            "Test Accuracy 0.52666664\n",
            "*****Iter 24900*****\n",
            "Train Loss: 0.5804607 Test Loss: 0.62283176\n",
            "Test Accuracy 0.47333333\n",
            "*****Iter 25000*****\n",
            "Train Loss: 0.5813572 Test Loss: 0.5824481\n",
            "Test Accuracy 0.59\n",
            "K: 1, N: 4\n",
            "*****Iter 100*****\n",
            "Train Loss: 1.054275 Test Loss: 1.0427969\n",
            "Test Accuracy 0.25\n",
            "*****Iter 200*****\n",
            "Train Loss: 0.9503734 Test Loss: 0.94889534\n",
            "Test Accuracy 0.3375\n",
            "*****Iter 300*****\n",
            "Train Loss: 0.9476998 Test Loss: 0.9494011\n",
            "Test Accuracy 0.25\n",
            "*****Iter 400*****\n",
            "Train Loss: 0.94429356 Test Loss: 0.94537926\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 500*****\n",
            "Train Loss: 0.9535693 Test Loss: 0.9541427\n",
            "Test Accuracy 0.25\n",
            "*****Iter 600*****\n",
            "Train Loss: 0.9479834 Test Loss: 0.9473194\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 700*****\n",
            "Train Loss: 0.9469282 Test Loss: 0.9469196\n",
            "Test Accuracy 0.25\n",
            "*****Iter 800*****\n",
            "Train Loss: 0.9471117 Test Loss: 0.946992\n",
            "Test Accuracy 0.25\n",
            "*****Iter 900*****\n",
            "Train Loss: 0.94675744 Test Loss: 0.9478779\n",
            "Test Accuracy 0.2625\n",
            "*****Iter 1000*****\n",
            "Train Loss: 0.945987 Test Loss: 0.9479003\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1100*****\n",
            "Train Loss: 0.9447401 Test Loss: 0.9449691\n",
            "Test Accuracy 0.245\n",
            "*****Iter 1200*****\n",
            "Train Loss: 0.94363225 Test Loss: 0.944045\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1300*****\n",
            "Train Loss: 0.9420543 Test Loss: 0.9445126\n",
            "Test Accuracy 0.2575\n",
            "*****Iter 1400*****\n",
            "Train Loss: 0.94370896 Test Loss: 0.9433235\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1500*****\n",
            "Train Loss: 0.9435047 Test Loss: 0.9435687\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1600*****\n",
            "Train Loss: 0.94053113 Test Loss: 0.944307\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1700*****\n",
            "Train Loss: 0.9424821 Test Loss: 0.9439814\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1800*****\n",
            "Train Loss: 0.9436391 Test Loss: 0.9425455\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1900*****\n",
            "Train Loss: 0.9426358 Test Loss: 0.94495803\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2000*****\n",
            "Train Loss: 0.94349635 Test Loss: 0.94314504\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2100*****\n",
            "Train Loss: 0.93803227 Test Loss: 0.94296247\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2200*****\n",
            "Train Loss: 0.93631715 Test Loss: 0.9360688\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2300*****\n",
            "Train Loss: 0.93068326 Test Loss: 0.9465144\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2400*****\n",
            "Train Loss: 0.93799436 Test Loss: 0.93898875\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2500*****\n",
            "Train Loss: 0.93872654 Test Loss: 0.9313874\n",
            "Test Accuracy 0.2325\n",
            "*****Iter 2600*****\n",
            "Train Loss: 0.9380579 Test Loss: 0.944864\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2700*****\n",
            "Train Loss: 0.9274504 Test Loss: 0.93704635\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2800*****\n",
            "Train Loss: 0.9510932 Test Loss: 0.93231016\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 2900*****\n",
            "Train Loss: 0.9187555 Test Loss: 0.9354523\n",
            "Test Accuracy 0.16\n",
            "*****Iter 3000*****\n",
            "Train Loss: 0.9333265 Test Loss: 0.93506587\n",
            "Test Accuracy 0.31\n",
            "*****Iter 3100*****\n",
            "Train Loss: 0.93006796 Test Loss: 0.9260951\n",
            "Test Accuracy 0.19\n",
            "*****Iter 3200*****\n",
            "Train Loss: 0.92274475 Test Loss: 0.9293735\n",
            "Test Accuracy 0.24\n",
            "*****Iter 3300*****\n",
            "Train Loss: 0.93003416 Test Loss: 0.93037176\n",
            "Test Accuracy 0.29\n",
            "*****Iter 3400*****\n",
            "Train Loss: 0.9325882 Test Loss: 0.93510056\n",
            "Test Accuracy 0.2275\n",
            "*****Iter 3500*****\n",
            "Train Loss: 0.92984164 Test Loss: 0.9280617\n",
            "Test Accuracy 0.2175\n",
            "*****Iter 3600*****\n",
            "Train Loss: 0.9327415 Test Loss: 0.9300449\n",
            "Test Accuracy 0.2125\n",
            "*****Iter 3700*****\n",
            "Train Loss: 0.9299779 Test Loss: 0.92523456\n",
            "Test Accuracy 0.245\n",
            "*****Iter 3800*****\n",
            "Train Loss: 0.9289796 Test Loss: 0.913186\n",
            "Test Accuracy 0.255\n",
            "*****Iter 3900*****\n",
            "Train Loss: 0.9219603 Test Loss: 0.9241608\n",
            "Test Accuracy 0.1975\n",
            "*****Iter 4000*****\n",
            "Train Loss: 0.9322456 Test Loss: 0.9285753\n",
            "Test Accuracy 0.27\n",
            "*****Iter 4100*****\n",
            "Train Loss: 0.9188978 Test Loss: 0.9214296\n",
            "Test Accuracy 0.1975\n",
            "*****Iter 4200*****\n",
            "Train Loss: 0.9140323 Test Loss: 0.9279418\n",
            "Test Accuracy 0.3075\n",
            "*****Iter 4300*****\n",
            "Train Loss: 0.9272191 Test Loss: 0.9231535\n",
            "Test Accuracy 0.3575\n",
            "*****Iter 4400*****\n",
            "Train Loss: 0.929321 Test Loss: 0.9232618\n",
            "Test Accuracy 0.295\n",
            "*****Iter 4500*****\n",
            "Train Loss: 0.9310657 Test Loss: 0.93350106\n",
            "Test Accuracy 0.215\n",
            "*****Iter 4600*****\n",
            "Train Loss: 0.94472885 Test Loss: 0.92011833\n",
            "Test Accuracy 0.3475\n",
            "*****Iter 4700*****\n",
            "Train Loss: 0.9212946 Test Loss: 0.9208112\n",
            "Test Accuracy 0.2325\n",
            "*****Iter 4800*****\n",
            "Train Loss: 0.9188793 Test Loss: 0.90674573\n",
            "Test Accuracy 0.24\n",
            "*****Iter 4900*****\n",
            "Train Loss: 0.93221664 Test Loss: 0.9258808\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 5000*****\n",
            "Train Loss: 0.9132041 Test Loss: 0.93340665\n",
            "Test Accuracy 0.215\n",
            "*****Iter 5100*****\n",
            "Train Loss: 0.9073236 Test Loss: 0.92097956\n",
            "Test Accuracy 0.285\n",
            "*****Iter 5200*****\n",
            "Train Loss: 0.8972258 Test Loss: 0.91424674\n",
            "Test Accuracy 0.325\n",
            "*****Iter 5300*****\n",
            "Train Loss: 0.9120271 Test Loss: 0.9030935\n",
            "Test Accuracy 0.23\n",
            "*****Iter 5400*****\n",
            "Train Loss: 0.9273217 Test Loss: 0.8883598\n",
            "Test Accuracy 0.295\n",
            "*****Iter 5500*****\n",
            "Train Loss: 0.88351536 Test Loss: 0.90798587\n",
            "Test Accuracy 0.2975\n",
            "*****Iter 5600*****\n",
            "Train Loss: 0.92558825 Test Loss: 0.91272813\n",
            "Test Accuracy 0.2175\n",
            "*****Iter 5700*****\n",
            "Train Loss: 0.92296714 Test Loss: 0.9088417\n",
            "Test Accuracy 0.235\n",
            "*****Iter 5800*****\n",
            "Train Loss: 0.8821359 Test Loss: 0.9058331\n",
            "Test Accuracy 0.22\n",
            "*****Iter 5900*****\n",
            "Train Loss: 0.8931755 Test Loss: 0.89812803\n",
            "Test Accuracy 0.245\n",
            "*****Iter 6000*****\n",
            "Train Loss: 0.89171183 Test Loss: 0.9119579\n",
            "Test Accuracy 0.245\n",
            "*****Iter 6100*****\n",
            "Train Loss: 0.9076518 Test Loss: 0.9120085\n",
            "Test Accuracy 0.2375\n",
            "*****Iter 6200*****\n",
            "Train Loss: 0.90778434 Test Loss: 0.9156892\n",
            "Test Accuracy 0.2425\n",
            "*****Iter 6300*****\n",
            "Train Loss: 0.90572774 Test Loss: 0.91363955\n",
            "Test Accuracy 0.225\n",
            "*****Iter 6400*****\n",
            "Train Loss: 0.9769542 Test Loss: 0.8944438\n",
            "Test Accuracy 0.3625\n",
            "*****Iter 6500*****\n",
            "Train Loss: 0.9090458 Test Loss: 0.9170497\n",
            "Test Accuracy 0.2375\n",
            "*****Iter 6600*****\n",
            "Train Loss: 0.91863257 Test Loss: 0.9103461\n",
            "Test Accuracy 0.26\n",
            "*****Iter 6700*****\n",
            "Train Loss: 0.89089394 Test Loss: 0.8873278\n",
            "Test Accuracy 0.245\n",
            "*****Iter 6800*****\n",
            "Train Loss: 0.90793324 Test Loss: 0.897374\n",
            "Test Accuracy 0.2575\n",
            "*****Iter 6900*****\n",
            "Train Loss: 0.9013368 Test Loss: 0.89761513\n",
            "Test Accuracy 0.295\n",
            "*****Iter 7000*****\n",
            "Train Loss: 0.9073229 Test Loss: 0.9099807\n",
            "Test Accuracy 0.245\n",
            "*****Iter 7100*****\n",
            "Train Loss: 0.8875101 Test Loss: 0.90386766\n",
            "Test Accuracy 0.2325\n",
            "*****Iter 7200*****\n",
            "Train Loss: 0.920265 Test Loss: 0.9188131\n",
            "Test Accuracy 0.2275\n",
            "*****Iter 7300*****\n",
            "Train Loss: 0.8840945 Test Loss: 0.89147264\n",
            "Test Accuracy 0.295\n",
            "*****Iter 7400*****\n",
            "Train Loss: 0.92615414 Test Loss: 0.90435845\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 7500*****\n",
            "Train Loss: 0.88040006 Test Loss: 0.907283\n",
            "Test Accuracy 0.25\n",
            "*****Iter 7600*****\n",
            "Train Loss: 0.8992274 Test Loss: 0.91313547\n",
            "Test Accuracy 0.2375\n",
            "*****Iter 7700*****\n",
            "Train Loss: 0.9239181 Test Loss: 0.89509887\n",
            "Test Accuracy 0.2925\n",
            "*****Iter 7800*****\n",
            "Train Loss: 0.9028275 Test Loss: 0.90270317\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 7900*****\n",
            "Train Loss: 0.9042314 Test Loss: 0.88845336\n",
            "Test Accuracy 0.2675\n",
            "*****Iter 8000*****\n",
            "Train Loss: 0.9436701 Test Loss: 0.9073185\n",
            "Test Accuracy 0.23\n",
            "*****Iter 8100*****\n",
            "Train Loss: 0.9472728 Test Loss: 0.88982373\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 8200*****\n",
            "Train Loss: 0.88126653 Test Loss: 0.88996893\n",
            "Test Accuracy 0.265\n",
            "*****Iter 8300*****\n",
            "Train Loss: 0.88844234 Test Loss: 0.8970748\n",
            "Test Accuracy 0.235\n",
            "*****Iter 8400*****\n",
            "Train Loss: 0.882967 Test Loss: 0.9111949\n",
            "Test Accuracy 0.2325\n",
            "*****Iter 8500*****\n",
            "Train Loss: 0.9161558 Test Loss: 0.9155704\n",
            "Test Accuracy 0.225\n",
            "*****Iter 8600*****\n",
            "Train Loss: 0.8969296 Test Loss: 0.89991134\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 8700*****\n",
            "Train Loss: 0.8780476 Test Loss: 0.8953236\n",
            "Test Accuracy 0.3175\n",
            "*****Iter 8800*****\n",
            "Train Loss: 0.9214119 Test Loss: 0.8942892\n",
            "Test Accuracy 0.32\n",
            "*****Iter 8900*****\n",
            "Train Loss: 0.9202093 Test Loss: 0.88930655\n",
            "Test Accuracy 0.245\n",
            "*****Iter 9000*****\n",
            "Train Loss: 0.89917964 Test Loss: 0.8947795\n",
            "Test Accuracy 0.2775\n",
            "*****Iter 9100*****\n",
            "Train Loss: 0.8889185 Test Loss: 0.8885062\n",
            "Test Accuracy 0.2675\n",
            "*****Iter 9200*****\n",
            "Train Loss: 0.9007229 Test Loss: 0.8898389\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 9300*****\n",
            "Train Loss: 0.86933947 Test Loss: 0.893279\n",
            "Test Accuracy 0.295\n",
            "*****Iter 9400*****\n",
            "Train Loss: 0.90023184 Test Loss: 0.9138156\n",
            "Test Accuracy 0.23\n",
            "*****Iter 9500*****\n",
            "Train Loss: 0.912081 Test Loss: 0.90430963\n",
            "Test Accuracy 0.29\n",
            "*****Iter 9600*****\n",
            "Train Loss: 0.87843156 Test Loss: 0.8731802\n",
            "Test Accuracy 0.315\n",
            "*****Iter 9700*****\n",
            "Train Loss: 0.9036979 Test Loss: 0.8949362\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 9800*****\n",
            "Train Loss: 0.8925517 Test Loss: 0.88524365\n",
            "Test Accuracy 0.2425\n",
            "*****Iter 9900*****\n",
            "Train Loss: 0.882006 Test Loss: 0.8967441\n",
            "Test Accuracy 0.2425\n",
            "*****Iter 10000*****\n",
            "Train Loss: 0.8877641 Test Loss: 0.8879233\n",
            "Test Accuracy 0.2375\n",
            "*****Iter 10100*****\n",
            "Train Loss: 0.8989351 Test Loss: 0.8936289\n",
            "Test Accuracy 0.245\n",
            "*****Iter 10200*****\n",
            "Train Loss: 0.8877095 Test Loss: 0.9011877\n",
            "Test Accuracy 0.32\n",
            "*****Iter 10300*****\n",
            "Train Loss: 0.87306905 Test Loss: 0.8887149\n",
            "Test Accuracy 0.285\n",
            "*****Iter 10400*****\n",
            "Train Loss: 0.89482355 Test Loss: 0.89722717\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 10500*****\n",
            "Train Loss: 0.89151955 Test Loss: 0.9100248\n",
            "Test Accuracy 0.225\n",
            "*****Iter 10600*****\n",
            "Train Loss: 0.898696 Test Loss: 0.9007242\n",
            "Test Accuracy 0.305\n",
            "*****Iter 10700*****\n",
            "Train Loss: 0.88623464 Test Loss: 0.8993577\n",
            "Test Accuracy 0.2625\n",
            "*****Iter 10800*****\n",
            "Train Loss: 0.8987285 Test Loss: 0.8969629\n",
            "Test Accuracy 0.3075\n",
            "*****Iter 10900*****\n",
            "Train Loss: 0.8912732 Test Loss: 0.89824206\n",
            "Test Accuracy 0.2425\n",
            "*****Iter 11000*****\n",
            "Train Loss: 0.8781971 Test Loss: 0.89319015\n",
            "Test Accuracy 0.2725\n",
            "*****Iter 11100*****\n",
            "Train Loss: 0.8812629 Test Loss: 0.9194928\n",
            "Test Accuracy 0.225\n",
            "*****Iter 11200*****\n",
            "Train Loss: 0.87530315 Test Loss: 0.89773446\n",
            "Test Accuracy 0.295\n",
            "*****Iter 11300*****\n",
            "Train Loss: 0.89992374 Test Loss: 0.884903\n",
            "Test Accuracy 0.295\n",
            "*****Iter 11400*****\n",
            "Train Loss: 0.8622222 Test Loss: 0.89726526\n",
            "Test Accuracy 0.29\n",
            "*****Iter 11500*****\n",
            "Train Loss: 0.885064 Test Loss: 0.90433097\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 11600*****\n",
            "Train Loss: 0.8660913 Test Loss: 0.8999838\n",
            "Test Accuracy 0.24\n",
            "*****Iter 11700*****\n",
            "Train Loss: 0.8810109 Test Loss: 0.89731926\n",
            "Test Accuracy 0.31\n",
            "*****Iter 11800*****\n",
            "Train Loss: 0.89100456 Test Loss: 0.897728\n",
            "Test Accuracy 0.2975\n",
            "*****Iter 11900*****\n",
            "Train Loss: 0.89772666 Test Loss: 0.8944277\n",
            "Test Accuracy 0.25\n",
            "*****Iter 12000*****\n",
            "Train Loss: 0.90822303 Test Loss: 0.88821495\n",
            "Test Accuracy 0.24\n",
            "*****Iter 12100*****\n",
            "Train Loss: 0.89594674 Test Loss: 0.8897763\n",
            "Test Accuracy 0.2375\n",
            "*****Iter 12200*****\n",
            "Train Loss: 0.8866948 Test Loss: 0.90128297\n",
            "Test Accuracy 0.23\n",
            "*****Iter 12300*****\n",
            "Train Loss: 0.9053787 Test Loss: 0.8999701\n",
            "Test Accuracy 0.26\n",
            "*****Iter 12400*****\n",
            "Train Loss: 0.8845837 Test Loss: 0.89352846\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 12500*****\n",
            "Train Loss: 0.9025953 Test Loss: 0.9057144\n",
            "Test Accuracy 0.235\n",
            "*****Iter 12600*****\n",
            "Train Loss: 0.8842831 Test Loss: 0.9075467\n",
            "Test Accuracy 0.255\n",
            "*****Iter 12700*****\n",
            "Train Loss: 0.90671843 Test Loss: 0.9000171\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 12800*****\n",
            "Train Loss: 0.90206456 Test Loss: 0.8900142\n",
            "Test Accuracy 0.245\n",
            "*****Iter 12900*****\n",
            "Train Loss: 0.89939946 Test Loss: 0.8871871\n",
            "Test Accuracy 0.285\n",
            "*****Iter 13000*****\n",
            "Train Loss: 0.8541349 Test Loss: 0.8936407\n",
            "Test Accuracy 0.245\n",
            "*****Iter 13100*****\n",
            "Train Loss: 0.9006663 Test Loss: 0.90775114\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 13200*****\n",
            "Train Loss: 0.88807464 Test Loss: 0.9053843\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 13300*****\n",
            "Train Loss: 0.87915766 Test Loss: 0.89486635\n",
            "Test Accuracy 0.2625\n",
            "*****Iter 13400*****\n",
            "Train Loss: 0.89572924 Test Loss: 0.88617086\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 13500*****\n",
            "Train Loss: 0.89554954 Test Loss: 0.88989854\n",
            "Test Accuracy 0.305\n",
            "*****Iter 13600*****\n",
            "Train Loss: 0.94919515 Test Loss: 0.88436776\n",
            "Test Accuracy 0.29\n",
            "*****Iter 13700*****\n",
            "Train Loss: 0.8521795 Test Loss: 0.8915727\n",
            "Test Accuracy 0.245\n",
            "*****Iter 13800*****\n",
            "Train Loss: 0.91603386 Test Loss: 0.8891666\n",
            "Test Accuracy 0.2825\n",
            "*****Iter 13900*****\n",
            "Train Loss: 0.883554 Test Loss: 0.88867104\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 14000*****\n",
            "Train Loss: 0.8868605 Test Loss: 0.89143133\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 14100*****\n",
            "Train Loss: 0.8641969 Test Loss: 0.89613616\n",
            "Test Accuracy 0.2375\n",
            "*****Iter 14200*****\n",
            "Train Loss: 0.86730045 Test Loss: 0.86839974\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 14300*****\n",
            "Train Loss: 0.9025346 Test Loss: 0.894009\n",
            "Test Accuracy 0.31\n",
            "*****Iter 14400*****\n",
            "Train Loss: 0.84793377 Test Loss: 0.8998536\n",
            "Test Accuracy 0.285\n",
            "*****Iter 14500*****\n",
            "Train Loss: 0.8656284 Test Loss: 0.8873055\n",
            "Test Accuracy 0.295\n",
            "*****Iter 14600*****\n",
            "Train Loss: 0.9193327 Test Loss: 0.898408\n",
            "Test Accuracy 0.23\n",
            "*****Iter 14700*****\n",
            "Train Loss: 0.8857987 Test Loss: 0.89477754\n",
            "Test Accuracy 0.2425\n",
            "*****Iter 14800*****\n",
            "Train Loss: 0.9104299 Test Loss: 0.8998813\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 14900*****\n",
            "Train Loss: 0.8997857 Test Loss: 0.88004196\n",
            "Test Accuracy 0.285\n",
            "*****Iter 15000*****\n",
            "Train Loss: 0.9037988 Test Loss: 0.89106154\n",
            "Test Accuracy 0.2625\n",
            "*****Iter 15100*****\n",
            "Train Loss: 0.90306735 Test Loss: 0.9048866\n",
            "Test Accuracy 0.24\n",
            "*****Iter 15200*****\n",
            "Train Loss: 0.86242425 Test Loss: 0.9009288\n",
            "Test Accuracy 0.285\n",
            "*****Iter 15300*****\n",
            "Train Loss: 0.8914182 Test Loss: 0.8956952\n",
            "Test Accuracy 0.2575\n",
            "*****Iter 15400*****\n",
            "Train Loss: 0.8999481 Test Loss: 0.89470476\n",
            "Test Accuracy 0.305\n",
            "*****Iter 15500*****\n",
            "Train Loss: 0.9017943 Test Loss: 0.9081639\n",
            "Test Accuracy 0.245\n",
            "*****Iter 15600*****\n",
            "Train Loss: 0.9040724 Test Loss: 0.88396317\n",
            "Test Accuracy 0.315\n",
            "*****Iter 15700*****\n",
            "Train Loss: 0.886973 Test Loss: 0.90852094\n",
            "Test Accuracy 0.24\n",
            "*****Iter 15800*****\n",
            "Train Loss: 0.8978519 Test Loss: 0.88849825\n",
            "Test Accuracy 0.245\n",
            "*****Iter 15900*****\n",
            "Train Loss: 0.8905168 Test Loss: 0.88794726\n",
            "Test Accuracy 0.31\n",
            "*****Iter 16000*****\n",
            "Train Loss: 0.8885106 Test Loss: 0.89694124\n",
            "Test Accuracy 0.245\n",
            "*****Iter 16100*****\n",
            "Train Loss: 0.8869569 Test Loss: 0.8905508\n",
            "Test Accuracy 0.27\n",
            "*****Iter 16200*****\n",
            "Train Loss: 0.89130956 Test Loss: 0.8935983\n",
            "Test Accuracy 0.25\n",
            "*****Iter 16300*****\n",
            "Train Loss: 0.86972 Test Loss: 0.8977169\n",
            "Test Accuracy 0.2725\n",
            "*****Iter 16400*****\n",
            "Train Loss: 0.89747393 Test Loss: 0.90539473\n",
            "Test Accuracy 0.245\n",
            "*****Iter 16500*****\n",
            "Train Loss: 0.9168503 Test Loss: 0.88535357\n",
            "Test Accuracy 0.305\n",
            "*****Iter 16600*****\n",
            "Train Loss: 0.89226246 Test Loss: 0.8828051\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 16700*****\n",
            "Train Loss: 0.8650569 Test Loss: 0.8853119\n",
            "Test Accuracy 0.29\n",
            "*****Iter 16800*****\n",
            "Train Loss: 0.9034756 Test Loss: 0.8824935\n",
            "Test Accuracy 0.305\n",
            "*****Iter 16900*****\n",
            "Train Loss: 0.8940277 Test Loss: 0.89102364\n",
            "Test Accuracy 0.3\n",
            "*****Iter 17000*****\n",
            "Train Loss: 0.9204564 Test Loss: 0.8775572\n",
            "Test Accuracy 0.295\n",
            "*****Iter 17100*****\n",
            "Train Loss: 0.90666294 Test Loss: 0.9030113\n",
            "Test Accuracy 0.2425\n",
            "*****Iter 17200*****\n",
            "Train Loss: 0.8830073 Test Loss: 0.89483964\n",
            "Test Accuracy 0.25\n",
            "*****Iter 17300*****\n",
            "Train Loss: 0.881738 Test Loss: 0.8819819\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 17400*****\n",
            "Train Loss: 0.8881054 Test Loss: 0.8924612\n",
            "Test Accuracy 0.285\n",
            "*****Iter 17500*****\n",
            "Train Loss: 0.8971398 Test Loss: 0.8921236\n",
            "Test Accuracy 0.2575\n",
            "*****Iter 17600*****\n",
            "Train Loss: 0.86180556 Test Loss: 0.898592\n",
            "Test Accuracy 0.2975\n",
            "*****Iter 17700*****\n",
            "Train Loss: 0.89112806 Test Loss: 0.89511865\n",
            "Test Accuracy 0.2325\n",
            "*****Iter 17800*****\n",
            "Train Loss: 0.8887006 Test Loss: 0.88579184\n",
            "Test Accuracy 0.27\n",
            "*****Iter 17900*****\n",
            "Train Loss: 0.8609754 Test Loss: 0.8848904\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 18000*****\n",
            "Train Loss: 0.89019316 Test Loss: 0.8909814\n",
            "Test Accuracy 0.3\n",
            "*****Iter 18100*****\n",
            "Train Loss: 0.90082 Test Loss: 0.89189035\n",
            "Test Accuracy 0.2925\n",
            "*****Iter 18200*****\n",
            "Train Loss: 0.89993143 Test Loss: 0.8898827\n",
            "Test Accuracy 0.31\n",
            "*****Iter 18300*****\n",
            "Train Loss: 0.909169 Test Loss: 0.9018923\n",
            "Test Accuracy 0.255\n",
            "*****Iter 18400*****\n",
            "Train Loss: 0.8679702 Test Loss: 0.873091\n",
            "Test Accuracy 0.3\n",
            "*****Iter 18500*****\n",
            "Train Loss: 0.8837981 Test Loss: 0.8930675\n",
            "Test Accuracy 0.305\n",
            "*****Iter 18600*****\n",
            "Train Loss: 0.88436556 Test Loss: 0.893538\n",
            "Test Accuracy 0.2925\n",
            "*****Iter 18700*****\n",
            "Train Loss: 0.9017203 Test Loss: 0.8882509\n",
            "Test Accuracy 0.28\n",
            "*****Iter 18800*****\n",
            "Train Loss: 0.91055024 Test Loss: 0.8914831\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 18900*****\n",
            "Train Loss: 0.89822626 Test Loss: 0.9011124\n",
            "Test Accuracy 0.255\n",
            "*****Iter 19000*****\n",
            "Train Loss: 0.85786295 Test Loss: 0.8852076\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 19100*****\n",
            "Train Loss: 0.9097115 Test Loss: 0.8820827\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 19200*****\n",
            "Train Loss: 0.90445924 Test Loss: 0.8896891\n",
            "Test Accuracy 0.255\n",
            "*****Iter 19300*****\n",
            "Train Loss: 0.9028535 Test Loss: 0.9038896\n",
            "Test Accuracy 0.235\n",
            "*****Iter 19400*****\n",
            "Train Loss: 0.89025694 Test Loss: 0.8909192\n",
            "Test Accuracy 0.255\n",
            "*****Iter 19500*****\n",
            "Train Loss: 0.8876705 Test Loss: 0.9086586\n",
            "Test Accuracy 0.2375\n",
            "*****Iter 19600*****\n",
            "Train Loss: 0.9062549 Test Loss: 0.90054685\n",
            "Test Accuracy 0.25\n",
            "*****Iter 19700*****\n",
            "Train Loss: 0.8955883 Test Loss: 0.8889328\n",
            "Test Accuracy 0.2775\n",
            "*****Iter 19800*****\n",
            "Train Loss: 0.8801491 Test Loss: 0.89798737\n",
            "Test Accuracy 0.25\n",
            "*****Iter 19900*****\n",
            "Train Loss: 0.90222454 Test Loss: 0.9084331\n",
            "Test Accuracy 0.24\n",
            "*****Iter 20000*****\n",
            "Train Loss: 0.88341075 Test Loss: 0.884624\n",
            "Test Accuracy 0.29\n",
            "*****Iter 20100*****\n",
            "Train Loss: 0.9048492 Test Loss: 0.89781904\n",
            "Test Accuracy 0.275\n",
            "*****Iter 20200*****\n",
            "Train Loss: 0.8710702 Test Loss: 0.885988\n",
            "Test Accuracy 0.27\n",
            "*****Iter 20300*****\n",
            "Train Loss: 0.87767565 Test Loss: 0.88835055\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 20400*****\n",
            "Train Loss: 0.8872311 Test Loss: 0.8885534\n",
            "Test Accuracy 0.255\n",
            "*****Iter 20500*****\n",
            "Train Loss: 0.881492 Test Loss: 0.8861245\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 20600*****\n",
            "Train Loss: 0.8817657 Test Loss: 0.89312583\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 20700*****\n",
            "Train Loss: 0.9123839 Test Loss: 0.87999046\n",
            "Test Accuracy 0.2925\n",
            "*****Iter 20800*****\n",
            "Train Loss: 0.91162366 Test Loss: 0.87813455\n",
            "Test Accuracy 0.32\n",
            "*****Iter 20900*****\n",
            "Train Loss: 0.894551 Test Loss: 0.8953549\n",
            "Test Accuracy 0.255\n",
            "*****Iter 21000*****\n",
            "Train Loss: 0.8934189 Test Loss: 0.8828452\n",
            "Test Accuracy 0.2925\n",
            "*****Iter 21100*****\n",
            "Train Loss: 0.87838507 Test Loss: 0.884704\n",
            "Test Accuracy 0.3\n",
            "*****Iter 21200*****\n",
            "Train Loss: 0.922209 Test Loss: 0.89497423\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 21300*****\n",
            "Train Loss: 0.8670473 Test Loss: 0.8891677\n",
            "Test Accuracy 0.2575\n",
            "*****Iter 21400*****\n",
            "Train Loss: 0.8939613 Test Loss: 0.8919258\n",
            "Test Accuracy 0.285\n",
            "*****Iter 21500*****\n",
            "Train Loss: 0.8782705 Test Loss: 0.8942755\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 21600*****\n",
            "Train Loss: 0.8820072 Test Loss: 0.8937765\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 21700*****\n",
            "Train Loss: 0.90641654 Test Loss: 0.91033417\n",
            "Test Accuracy 0.2125\n",
            "*****Iter 21800*****\n",
            "Train Loss: 0.8465358 Test Loss: 0.8803769\n",
            "Test Accuracy 0.265\n",
            "*****Iter 21900*****\n",
            "Train Loss: 0.85693896 Test Loss: 0.8801823\n",
            "Test Accuracy 0.305\n",
            "*****Iter 22000*****\n",
            "Train Loss: 0.8825647 Test Loss: 0.8782367\n",
            "Test Accuracy 0.2775\n",
            "*****Iter 22100*****\n",
            "Train Loss: 0.8668918 Test Loss: 0.88411856\n",
            "Test Accuracy 0.2825\n",
            "*****Iter 22200*****\n",
            "Train Loss: 0.87779456 Test Loss: 0.8897977\n",
            "Test Accuracy 0.2775\n",
            "*****Iter 22300*****\n",
            "Train Loss: 0.86096054 Test Loss: 0.90793073\n",
            "Test Accuracy 0.2475\n",
            "*****Iter 22400*****\n",
            "Train Loss: 0.87213147 Test Loss: 0.89623797\n",
            "Test Accuracy 0.225\n",
            "*****Iter 22500*****\n",
            "Train Loss: 0.87561804 Test Loss: 0.9028928\n",
            "Test Accuracy 0.26\n",
            "*****Iter 22600*****\n",
            "Train Loss: 0.8981139 Test Loss: 0.8813085\n",
            "Test Accuracy 0.28\n",
            "*****Iter 22700*****\n",
            "Train Loss: 0.8844666 Test Loss: 0.889055\n",
            "Test Accuracy 0.26\n",
            "*****Iter 22800*****\n",
            "Train Loss: 0.92828023 Test Loss: 0.927428\n",
            "Test Accuracy 0.2025\n",
            "*****Iter 22900*****\n",
            "Train Loss: 0.87768173 Test Loss: 0.8827352\n",
            "Test Accuracy 0.2875\n",
            "*****Iter 23000*****\n",
            "Train Loss: 0.8783001 Test Loss: 0.89492065\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 23100*****\n",
            "Train Loss: 0.8706932 Test Loss: 0.8922783\n",
            "Test Accuracy 0.3\n",
            "*****Iter 23200*****\n",
            "Train Loss: 0.8989245 Test Loss: 0.8936781\n",
            "Test Accuracy 0.2675\n",
            "*****Iter 23300*****\n",
            "Train Loss: 0.8845476 Test Loss: 0.88310003\n",
            "Test Accuracy 0.2975\n",
            "*****Iter 23400*****\n",
            "Train Loss: 0.87203515 Test Loss: 0.89352286\n",
            "Test Accuracy 0.305\n",
            "*****Iter 23500*****\n",
            "Train Loss: 0.8724327 Test Loss: 0.9119696\n",
            "Test Accuracy 0.235\n",
            "*****Iter 23600*****\n",
            "Train Loss: 0.86998266 Test Loss: 0.88615775\n",
            "Test Accuracy 0.295\n",
            "*****Iter 23700*****\n",
            "Train Loss: 0.8908566 Test Loss: 0.8906717\n",
            "Test Accuracy 0.2925\n",
            "*****Iter 23800*****\n",
            "Train Loss: 0.91011935 Test Loss: 0.8955031\n",
            "Test Accuracy 0.33\n",
            "*****Iter 23900*****\n",
            "Train Loss: 0.8704246 Test Loss: 0.89705557\n",
            "Test Accuracy 0.275\n",
            "*****Iter 24000*****\n",
            "Train Loss: 0.89349955 Test Loss: 0.87853706\n",
            "Test Accuracy 0.275\n",
            "*****Iter 24100*****\n",
            "Train Loss: 0.88126934 Test Loss: 0.8770662\n",
            "Test Accuracy 0.3075\n",
            "*****Iter 24200*****\n",
            "Train Loss: 0.8637408 Test Loss: 0.8951452\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 24300*****\n",
            "Train Loss: 0.8893825 Test Loss: 0.8802996\n",
            "Test Accuracy 0.2825\n",
            "*****Iter 24400*****\n",
            "Train Loss: 0.8731424 Test Loss: 0.91001993\n",
            "Test Accuracy 0.2425\n",
            "*****Iter 24500*****\n",
            "Train Loss: 0.8798872 Test Loss: 0.8912458\n",
            "Test Accuracy 0.2575\n",
            "*****Iter 24600*****\n",
            "Train Loss: 0.8684482 Test Loss: 0.887141\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 24700*****\n",
            "Train Loss: 0.8914109 Test Loss: 0.88503385\n",
            "Test Accuracy 0.3\n",
            "*****Iter 24800*****\n",
            "Train Loss: 0.9004949 Test Loss: 0.8910221\n",
            "Test Accuracy 0.3025\n",
            "*****Iter 24900*****\n",
            "Train Loss: 0.8825424 Test Loss: 0.8863231\n",
            "Test Accuracy 0.2725\n",
            "*****Iter 25000*****\n",
            "Train Loss: 0.88755673 Test Loss: 0.89939845\n",
            "Test Accuracy 0.2875\n",
            "K: 5, N: 4\n",
            "*****Iter 100*****\n",
            "Train Loss: 0.7736724 Test Loss: 0.83429146\n",
            "Test Accuracy 0.0\n",
            "*****Iter 200*****\n",
            "Train Loss: 0.6760287 Test Loss: 0.7519231\n",
            "Test Accuracy 0.25\n",
            "*****Iter 300*****\n",
            "Train Loss: 0.8076388 Test Loss: 0.7456235\n",
            "Test Accuracy 0.25\n",
            "*****Iter 400*****\n",
            "Train Loss: 0.7250299 Test Loss: 0.6906799\n",
            "Test Accuracy 0.5\n",
            "*****Iter 500*****\n",
            "Train Loss: 0.66056323 Test Loss: 0.772556\n",
            "Test Accuracy 0.0325\n",
            "*****Iter 600*****\n",
            "Train Loss: 0.65504694 Test Loss: 0.694647\n",
            "Test Accuracy 0.5\n",
            "*****Iter 700*****\n",
            "Train Loss: 0.7326098 Test Loss: 0.7674926\n",
            "Test Accuracy 0.1225\n",
            "*****Iter 800*****\n",
            "Train Loss: 0.6747884 Test Loss: 0.67487466\n",
            "Test Accuracy 0.495\n",
            "*****Iter 900*****\n",
            "Train Loss: 0.7125351 Test Loss: 0.7084802\n",
            "Test Accuracy 0.195\n",
            "*****Iter 1000*****\n",
            "Train Loss: 0.7070592 Test Loss: 0.70879483\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1100*****\n",
            "Train Loss: 0.70596033 Test Loss: 0.6995414\n",
            "Test Accuracy 0.2625\n",
            "*****Iter 1200*****\n",
            "Train Loss: 0.7297251 Test Loss: 0.7240752\n",
            "Test Accuracy 0.1675\n",
            "*****Iter 1300*****\n",
            "Train Loss: 0.71100706 Test Loss: 0.7237972\n",
            "Test Accuracy 0.23\n",
            "*****Iter 1400*****\n",
            "Train Loss: 0.7024932 Test Loss: 0.7051427\n",
            "Test Accuracy 0.25\n",
            "*****Iter 1500*****\n",
            "Train Loss: 0.70998096 Test Loss: 0.6962089\n",
            "Test Accuracy 0.27\n",
            "*****Iter 1600*****\n",
            "Train Loss: 0.6689499 Test Loss: 0.8151306\n",
            "Test Accuracy 0.0\n",
            "*****Iter 1700*****\n",
            "Train Loss: 0.7258722 Test Loss: 0.67751044\n",
            "Test Accuracy 0.4875\n",
            "*****Iter 1800*****\n",
            "Train Loss: 0.6831252 Test Loss: 0.7201121\n",
            "Test Accuracy 0.235\n",
            "*****Iter 1900*****\n",
            "Train Loss: 0.70417285 Test Loss: 0.7055777\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2000*****\n",
            "Train Loss: 0.7046065 Test Loss: 0.7051906\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2100*****\n",
            "Train Loss: 0.71073633 Test Loss: 0.709872\n",
            "Test Accuracy 0.25\n",
            "*****Iter 2200*****\n",
            "Train Loss: 0.72895455 Test Loss: 0.64681256\n",
            "Test Accuracy 0.595\n",
            "*****Iter 2300*****\n",
            "Train Loss: 0.7017061 Test Loss: 0.6988613\n",
            "Test Accuracy 0.2725\n",
            "*****Iter 2400*****\n",
            "Train Loss: 0.7074358 Test Loss: 0.7117881\n",
            "Test Accuracy 0.3175\n",
            "*****Iter 2500*****\n",
            "Train Loss: 0.69365674 Test Loss: 0.6828424\n",
            "Test Accuracy 0.37\n",
            "*****Iter 2600*****\n",
            "Train Loss: 0.6981416 Test Loss: 0.7090305\n",
            "Test Accuracy 0.2575\n",
            "*****Iter 2700*****\n",
            "Train Loss: 0.7056182 Test Loss: 0.7048766\n",
            "Test Accuracy 0.2525\n",
            "*****Iter 2800*****\n",
            "Train Loss: 0.7171727 Test Loss: 0.6925843\n",
            "Test Accuracy 0.28\n",
            "*****Iter 2900*****\n",
            "Train Loss: 0.689359 Test Loss: 0.6935088\n",
            "Test Accuracy 0.2325\n",
            "*****Iter 3000*****\n",
            "Train Loss: 0.67300135 Test Loss: 0.70451635\n",
            "Test Accuracy 0.3175\n",
            "*****Iter 3100*****\n",
            "Train Loss: 0.6895013 Test Loss: 0.6796185\n",
            "Test Accuracy 0.3575\n",
            "*****Iter 3200*****\n",
            "Train Loss: 0.6973786 Test Loss: 0.6687821\n",
            "Test Accuracy 0.475\n",
            "*****Iter 3300*****\n",
            "Train Loss: 0.6852177 Test Loss: 0.6723403\n",
            "Test Accuracy 0.42\n",
            "*****Iter 3400*****\n",
            "Train Loss: 0.6821139 Test Loss: 0.6659139\n",
            "Test Accuracy 0.46\n",
            "*****Iter 3500*****\n",
            "Train Loss: 0.66546816 Test Loss: 0.67387474\n",
            "Test Accuracy 0.405\n",
            "*****Iter 3600*****\n",
            "Train Loss: 0.666524 Test Loss: 0.6647287\n",
            "Test Accuracy 0.4575\n",
            "*****Iter 3700*****\n",
            "Train Loss: 0.6621254 Test Loss: 0.663503\n",
            "Test Accuracy 0.45\n",
            "*****Iter 3800*****\n",
            "Train Loss: 0.67551655 Test Loss: 0.6508305\n",
            "Test Accuracy 0.5575\n",
            "*****Iter 3900*****\n",
            "Train Loss: 0.65679497 Test Loss: 0.6501949\n",
            "Test Accuracy 0.5375\n",
            "*****Iter 4000*****\n",
            "Train Loss: 0.6638486 Test Loss: 0.6667691\n",
            "Test Accuracy 0.415\n",
            "*****Iter 4100*****\n",
            "Train Loss: 0.66475385 Test Loss: 0.65591466\n",
            "Test Accuracy 0.495\n",
            "*****Iter 4200*****\n",
            "Train Loss: 0.64469105 Test Loss: 0.6626275\n",
            "Test Accuracy 0.455\n",
            "*****Iter 4300*****\n",
            "Train Loss: 0.6518306 Test Loss: 0.6471186\n",
            "Test Accuracy 0.55\n",
            "*****Iter 4400*****\n",
            "Train Loss: 0.63997555 Test Loss: 0.6429135\n",
            "Test Accuracy 0.5675\n",
            "*****Iter 4500*****\n",
            "Train Loss: 0.6585328 Test Loss: 0.65280986\n",
            "Test Accuracy 0.53\n",
            "*****Iter 4600*****\n",
            "Train Loss: 0.67299074 Test Loss: 0.6494751\n",
            "Test Accuracy 0.525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG1Y7X31-AXg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ze7a9OYBrQd"
      },
      "source": [
        "for conf, loss in test_acc_dict.items():\n",
        "  iter_grid = np.arange(0, 25100, 100)\n",
        "  K, N = conf\n",
        "  plt.plot(iter_grid, loss, label='K:{:d}, N:{:d}'.format(K, N))\n",
        "plt.legend()\n",
        "plt.ylabel('Test accuracy')\n",
        "plt.xlabel('Iterations')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}